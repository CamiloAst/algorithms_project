@article{ROOS2020112975,
title = {Online conferences – Towards a new (virtual) reality},
journal = {Computational and Theoretical Chemistry},
volume = {1189},
pages = {112975},
year = {2020},
issn = {2210-271X},
doi = {https://doi.org/10.1016/j.comptc.2020.112975},
url = {https://www.sciencedirect.com/science/article/pii/S2210271X20302759},
author = {Goedele Roos and Julianna Oláh and Rebecca Ingle and Rika Kobayashi and Milica Feldt},
keywords = {Virtual conference, Virtual Winter School on Computational Chemistry, Hybrid online/in-person conference},
abstract = {The recent article: Nature 579, 327–328 (2020), ending with the phrase: “You can’t just suddenly make a conference be online.”, has motivated us to write about the practicalities and philosophy of running online events, drawing on our extensive experience running an annual online computational chemistry conference. Our goals for this online conference series have always been: (1) Availability; (2) Community building and (3) Supporting young scientists. In this article, we highlight the motivations behind our initiative, how this has influenced the organisation of our online meeting, and discuss the benefits as well as the drawbacks of virtual meetings. Virtual conferences may not fully replace in-person meetings, but they are rapidly becoming an accepted alternative format. We discuss the hybrid online/in-person conference format as a future possibility that may offer an opportunity to reduce the environmental impact and accessibility barriers associate with in-person meetings without comprising networking and community-building opportunities.}
}
@article{CHANG201323,
title = {Discovering Taiwanese design college students’ learning performance and imaginative capacity},
journal = {Thinking Skills and Creativity},
volume = {10},
pages = {23-39},
year = {2013},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2013.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S1871187113000266},
author = {Hsiang-Tang Chang and Tung-I. Lin},
keywords = {Imaginative capacity, Imagination, Learning performance, Design college, RASCH measurement},
abstract = {Imagination affects not only the structure of design ideas at the initial stage but also influences the manifestation of final products. The purpose of this study was to investigate the association between Taiwanese design college students’ imaginative capacity and their learning performance in class. On the basis of recent scholarship, the authors proposed several reasonably related factors, which were classified into three aspects: personality traits, learning atmosphere, and imaginative thinking. They then verified and discussed four research questions through a teaching experiment with 63 junior college students in YunTech, Taiwan. To proceed smoothly without significantly changing the current teaching process, the authors developed a set of supplementary teaching material and two sets of questionnaires which they then used in the teaching experiment. The results of the teaching experiment proved and suggested the following points corresponding to the research questions: (1) students’ senior high school backgrounds have an effect on their imaginative capacities; (2) judges from other schools should be invited to join the judgement to ensure fairness and with a broader scope; (3) students’ imaginative capacity indeed has an effect on the grade of their final products in the judgement; (4) teachers can identify students with higher imaginative capacity through the responses to the proposed supplementary teaching materials and questionnaires used in the study's curricula. Furthermore, the supplementary teaching material is conjectured to be able to inspire students’ imaginative capacity.}
}
@article{MANLEY201427,
title = {A framework for simulating large-scale complex urban traffic dynamics through hybrid agent-based modelling},
journal = {Computers, Environment and Urban Systems},
volume = {44},
pages = {27-36},
year = {2014},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2013.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0198971513001129},
author = {Ed Manley and Tao Cheng and Alan Penn and Andy Emmonds},
keywords = {Agent-based simulation, Urban complexity, Human cognition, Collective phenomena, Traffic flow, Hybrid simulation},
abstract = {Urban road traffic dynamics are the product of the behaviours and interactions of thousands, often millions of individuals. Traditionally, models of these phenomena have incorporated simplistic representations of individual behaviour, ensuring the maximisation of simulation scale under given computational constraints. Yet, by simplifying representations of behaviour, the overall predictive capability of the model inevitably reduces. In this work a hybrid agent-based modelling framework is introduced that aims to balance the demands of behavioural realism and computational capacity, integrating a descriptive representation of driver behaviour with a simplified, collective model of traffic flow. The hybridisation of these approaches within an agent-based modelling framework yields a representation of urban traffic flow that is driven by individual behaviour, yet, in reducing the computational intensity of simulated physical interaction, enables the scalable expansion to large numbers of agents. A real-world proof-of-concept case study is presented, demonstrating the application of this approach, and showing the gains in computational efficiency made in utilising this approach against traditional agent-based approaches. The paper concludes in addressing how this model might be extended, and exploring the role hybrid agent-based modelling approaches may hold in the simulation of other complex urban phenomena.}
}
@incollection{FREUND20151,
title = {Chapter 1 - Introduction},
editor = {Jack Freund and Jack Jones},
booktitle = {Measuring and Managing Information Risk},
publisher = {Butterworth-Heinemann},
address = {Boston},
pages = {1-11},
year = {2015},
isbn = {978-0-12-420231-3},
doi = {https://doi.org/10.1016/B978-0-12-420231-3.00001-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780124202313000014},
author = {Jack Freund and Jack Jones},
keywords = {Analysis, Assessment, Assumptions, Bald tire, Risk, Threat, Vulnerability},
abstract = {This chapter makes the case for the need for quantitative risk management. It begins with the Bald Tire thought experiment to help make the case for a need to articulate assumptions, discuss terminology, and makes plain the factors of risk that we care about modeling and how to communicate them effectively to management. This section also discusses the difference between risk assessment and risk analysis, and details the deficiencies in current approaches that treat the two the same. Lastly, the chapter spells out the progression of topics for the remainder of the book and offers some words of advice on how thinking about risk will impact your ability to make better decisions in all aspects of your life.}
}
@article{XU2021104922,
title = {Brain decoding in multiple languages: Can cross-language brain decoding work?},
journal = {Brain and Language},
volume = {215},
pages = {104922},
year = {2021},
issn = {0093-934X},
doi = {https://doi.org/10.1016/j.bandl.2021.104922},
url = {https://www.sciencedirect.com/science/article/pii/S0093934X2100016X},
author = {Min Xu and Duo Li and Ping Li},
keywords = {Cross-language brain decoding, Neural representation, Multivariate pattern analysis, Computational modeling, Multilingualism},
abstract = {The approach of cross-language brain decoding is to use models of brain decoding from one language to decode stimuli of another language. It has the potential to provide new insights into how our brain represents multiple languages. While it is possible to decode semantic information across different languages from neuroimaging data, the approach’s overall success remains to be tested and depends on a number of factors such as cross-language similarity, age of acquisition/proficiency levels, and depth of language processing. We expect to see continued progress in this domain, from a traditional focus on words and concrete concepts toward the use of naturalistic experimental tasks involving higher-level language processing (e.g., discourse processing). The approach can also be applied to understand how cross-modal, cross-cultural, and other nonlinguistic factors may influence neural representations of different languages. This article provides an overview of cross-language brain decoding with suggestions for future research directions.}
}
@article{SATO2019293,
title = {Statistical analysis of word usage in biological publications since 1965: Historical delineation highlighting an emergence of function-oriented discourses in contemporary molecular and cellular biology},
journal = {Journal of Theoretical Biology},
volume = {462},
pages = {293-303},
year = {2019},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2018.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S0022519318305708},
author = {Naoki Sato and Kaoru Sato},
keywords = {Contemporary biology, Function, History of biology, Statistical text analysis, Role, Social responsibility of research},
abstract = {Typical studies on the history of science, or particularly of biology, have been focused on a particular scientist or book, but this selection has a risk of being arbitrary. To find a more objective way of studying history of biology, we applied a statistical method. First, we downloaded from the PubMed database all available titles and abstracts of 934,807 articles in 32 selected journals from 1965 to 2014, and extracted most frequently used 322 terms by text mining. Clustering of these terms according to the annual frequency of usage resulted in three main clusters: Cluster 1 represented terms that were no longer used frequently, Cluster 3 included terms that became abundantly used recently, and Cluster 2 contained terms constantly used. Three phases were delineated in the history of biology over the past 50 years, with transitions in 1987 and 1997. In contrast with our tacit understanding that “function” is a key notion in biological thinking, the results suggest that function-oriented discourses are a new habit of biologists in the genomic era after 1997, in which biological researches focus on identifying a link between a molecule or a structure with its function. We hypothesize that, in spite of repeated warnings, function-related discourses have a teleological connotation, which is easily misunderstood by general audience and, with emphatic expressions such as “important” and “essential”, fit to the need for justification of researches as part of researcher's responsibility for public funding.}
}
@article{MARUFA20241182,
title = {Educating Middle Adolescent through Social Media: The Impact of Early Marriage on Achieving High Education},
journal = {Procedia Computer Science},
volume = {245},
pages = {1182-1191},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.348},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031569},
author = {Riza Izzati Ma'rufa and Yudhistya Ayu Kusumawati and Asri Radhitanti},
keywords = {Social Media Campaign, Early Marriege, Quality Education, Women},
abstract = {Malang has become the city that reached the highest rate of early marriage in the Province of East Java. Many data had stated that Malang remained on the first rank for two years straight which is 2021 until 2022. This issue became the main cause of students dropping out of school and hampered in achieving higher education. Some of the factors that cause early marriage to remain unresolved are society's distorted perception of early marriage. Due to this issue, this study aimed to observe how (research output) can reduce the rate of early marriage especially in Malang. To acknowledge the problem, this study uses literature review and qualitative methods for data processing. Sources of this literature review are extracted from various journals that come from trusted sources. Based on the research results, it can be sensed that the influence of early marriage has a negative impact on educational attainment of adolescents especially on women. Due to high number of early marriages in Malang and the impact on educational attainment of female adolescents, this research resulting in social media campaign to educate adolescents about how early marriage impacts quality education. Therefore, it is hoped that this Instagram Platform Based Campaign will help to spread awareness among adolescents about how early marriage impacts their education and life goals.}
}
@article{HAO201630,
title = {Reflection enhances creativity: Beneficial effects of idea evaluation on idea generation},
journal = {Brain and Cognition},
volume = {103},
pages = {30-37},
year = {2016},
issn = {0278-2626},
doi = {https://doi.org/10.1016/j.bandc.2016.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0278262616300057},
author = {Ning Hao and Yixuan Ku and Meigui Liu and Yi Hu and Mark Bodner and Roland H. Grabner and Andreas Fink},
keywords = {Idea evaluation, Idea generation, Creativity, Alpha, EEG},
abstract = {The present study aimed to explore the neural correlates underlying the effects of idea evaluation on idea generation in creative thinking. Participants were required to generate original uses of conventional objects (alternative uses task) during EEG recording. A reflection task (mentally evaluating the generated ideas) or a distraction task (object characteristics task) was inserted into the course of idea generation. Behavioral results revealed that participants generated ideas with higher originality after evaluating the generated ideas than after performing the distraction task. The EEG results revealed that idea evaluation was accompanied with upper alpha (10–13Hz) synchronization, most prominent at frontal cortical sites. Moreover, upper alpha activity in frontal cortices during idea generation was enhanced after idea evaluation. These findings indicate that idea evaluation may elicit a state of heightened internal attention or top-down activity that facilitates efficient retrieval and integration of internal memory representations.}
}
@article{HUANG2024369,
title = {A linear-attention-combined convolutional neural network for EEG-based visual stimulus recognition},
journal = {Biocybernetics and Biomedical Engineering},
volume = {44},
number = {2},
pages = {369-379},
year = {2024},
issn = {0208-5216},
doi = {https://doi.org/10.1016/j.bbe.2024.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0208521624000299},
author = {Junjie Huang and Wanzhong Chen and Tao Zhang},
keywords = {Brain–computer interface (BCI), Convolutional neural network (CNN), Electroencephalogram (EEG), Linear attention mechanism, Visual stimulus recognition},
abstract = {The recognition task of visual stimuli based on EEG (Electroencephalogram) has become a major and important topic in the field of Brain–Computer Interfaces (BCI) research. Although the underlying spatial features of EEG can effectively represent visual stimulus information, it still remains a highly challenging task to explore the local–global information of the underlying EEG to achieve better decoding performance. Therefore, in this paper we propose a deep learning architecture called Linear-Attention-combined Convolutional Neural Network (LACNN) for visual stimuli EEG-based classification task. The proposed architecture combines the modules of Convolutional Neural Networks (CNN) and Linear Attention, effectively extracting local and global features of EEG for decoding while maintaining low computational complexity and model parameters. We conducted extensive experiments on a public EEG dataset from the Stanford Digital Repository. The experimental results demonstrate that LACNN achieves an average decoding accuracy of 54.13% and 29.83% in 6-category and 72-exemplar classification tasks respectively, outperforming the state-of-the-art methods, which indicates that our method can effectively decode visual stimuli from EEG. Further analysis of LACNN shows that the Linear Attention module improves the separability between different category features and localizes key brain region information that aligns with the paradigm principles.}
}
@article{POGGIO1981258,
title = {Marr's computational approach to vision},
journal = {Trends in Neurosciences},
volume = {4},
pages = {258-262},
year = {1981},
issn = {0166-2236},
doi = {https://doi.org/10.1016/0166-2236(81)90081-3},
url = {https://www.sciencedirect.com/science/article/pii/0166223681900813},
author = {T. Poggio},
abstract = {In the last 7 years a new computational approach has led to promising advances in our understanding of visual perception. The foundations of the approach, its overall framework and its first solid results are largely due to the work of a single man, David Marr at MIT. Now, after his death in Boston on 17 November, 1980, research in vision will never be the same.}
}
@article{DENG2023104944,
title = {A VR-based BCI interactive system for UAV swarm control},
journal = {Biomedical Signal Processing and Control},
volume = {85},
pages = {104944},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2023.104944},
url = {https://www.sciencedirect.com/science/article/pii/S1746809423003774},
author = {Tao Deng and Zhen Huo and Lihua Zhang and Zhiyan Dong and Lan Niu and Xiaoyang Kang and Xiuwei Huang},
keywords = {Brain-computer interface (BCI), Swarm control, Steady state visual evoked potential (SSVEP), Electroencephalogram (EEG), Unmanned Aerial Vehicle (UAV), Quadcopter, Virtual Reality (VR)},
abstract = {The traditional Unmanned Aerial Vehicle (UAV) swarm control mainly adopts the ground station method, which is too fixed, and the interaction is difficult to meet the high dynamic task requirements. There is an urgent need for new interaction methods to integrate the advantages of human thinking in dealing with uncertain problems. Nevertheless, brain-computer interface(BCI) technology is directly controlled by thoughts, one of the most promising next-generation human–computer interaction technologies. Therefore, in this study, we innovatively applied the BCI system based on Virtual Reality (VR) to the group UAV and realized a novel and intelligent group control method, which proposes new ideas and paradigms for the control of swarm UAVs in the future. Specifically, this study takes a quadcopter as an example. A modular and extensible multi-quadcopter system was created, and then a visual stimulation 3D VR scene system with a digital twin function was established. On this basis, the BCI system based on the Stable state visual evoked potential (SSVEP) paradigm was adopted for the swarm control of the quadcopter. The experimental results show that the formation control of multi-quadcopter is successfully realized by the subjects using the proposed VR-based BCI interactive system, with an accuracy rate of 90% and a good performance in information transmission rate. In addition, the immersive VR twin system established one-to-one for EEG signal acquisition allows subjects to have a better experience.}
}
@incollection{LU2024173,
title = {Chapter 13 - Collection and transmission planning for large offshore wind power base},
editor = {Zongxiang Lu and Haibo Li and Ying Qiao and Le Xie and Chanan Singh},
booktitle = {Power System Flexibility},
publisher = {Academic Press},
pages = {173-191},
year = {2024},
isbn = {978-0-323-99517-7},
doi = {https://doi.org/10.1016/B978-0-323-99517-7.00016-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323995177000166},
author = {Zongxiang Lu and Haibo Li and Ying Qiao and Le Xie and Chanan Singh},
keywords = {Mid- to offshore wind power, hierarchical planning, steepest descent method, minimum spanning tree algorithm, transmission equipment selection, improved ant colony algorithm},
abstract = {Offshore wind power planning in China thus far has generally inherited the principles and thinking of onshore wind power planning. Mid- to offshore wind power access could incur a cost far higher than that of onshore wind generation, accounting for 15%–30% of the total investment. Sea state resources, corridor resources, landing conditions, and submarine cable wiring all face materially contrasting constraints to onshore wind power, necessitating dedicated planning efforts for offshore wind power. In this chapter, a planning framework for the sequential and cascaded development of mid- to offshore wind power bases is proposed, and a tiered master planning approach featuring on-site, cluster, and AC/DC transmission is established, filling the gap in transmission planning of large-scale mid- to offshore wind farm clusters. Firstly, location optimization of offshore hub substations based on a steepest descent method is established and explaining its specific implementation methods. Secondly, an improved minimum spanning tree algorithm is used to find a topology connection method for the collector system with the optimal length of submarine cable, which makes the cost optimal. Finally, the optimization model of transmission equipment selection considering the risk of high wind speed truncation is established, and the topology optimization modeling method of offshore wind power cluster transmission systems based on the improved ant colony optimization algorithm is proposed.}
}
@article{MAFTEI2022107032,
title = {Using fake news as means of cyber-bullying: The link with compulsive internet use and online moral disengagement},
journal = {Computers in Human Behavior},
volume = {127},
pages = {107032},
year = {2022},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.107032},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221003551},
author = {Alexandra Maftei and Andrei-Corneliu Holman and Ioan-Alex Merlici},
keywords = {Fake news, Online moral disengagement, Cyberbullying, Compulsive internet use},
abstract = {Online moral disengagement and cyberbullying can enhance fake news spreading. We explored the links between these variables and compulsive Internet use in a sample of 509 teenagers and adults aged 11 to 67. We investigated the effect of compulsive Internet use on cyberbullying through fake news creation and/or distribution, both direct and via moral disengagement, and the related differences between adults and teenagers. The indirect effect of compulsive Internet use on cyberbullying through moral disengagement was significant in adolescents, but not in adults. As assumed, teenagers scored significantly higher than adults on all the primary variables. Contrary to our expectations, no significant gender differences emerged, regardless of participants' age, in terms of compulsive Internet use, moral disengagement, nor cyberbullying. The results emphasize the importance of relevant online education programs designed to engage both teenagers and adults in critical thinking that might help in the fake news detection process, especially during the COVID-19 pandemic.}
}
@article{RODRIGUEZ2024,
title = {Leveraging Generative AI Tools to Support the Development of Digital Solutions in Health Care Research: Case Study},
journal = {JMIR Human Factors},
volume = {11},
year = {2024},
issn = {2292-9495},
doi = {https://doi.org/10.2196/52885},
url = {https://www.sciencedirect.com/science/article/pii/S2292949524000245},
author = {Danissa V Rodriguez and Katharine Lawrence and Javier Gonzalez and Beatrix Brandfield-Harvey and Lynn Xu and Sumaiya Tasneem and Defne L Levine and Devin Mann},
keywords = {digital health, GenAI, generative, artificial intelligence, ChatGPT, software engineering, mHealth, mobile health, app, apps, application, applications, diabetes, diabetic, diabetes prevention, digital prescription, software, engagement, behaviour change, behavior change, developer, developers, LLM, LLMs, language model, language models, NLP, natural language processing},
abstract = {Background
Generative artificial intelligence has the potential to revolutionize health technology product development by improving coding quality, efficiency, documentation, quality assessment and review, and troubleshooting.
Objective
This paper explores the application of a commercially available generative artificial intelligence tool (ChatGPT) to the development of a digital health behavior change intervention designed to support patient engagement in a commercial digital diabetes prevention program.
Methods
We examined the capacity, advantages, and limitations of ChatGPT to support digital product idea conceptualization, intervention content development, and the software engineering process, including software requirement generation, software design, and code production. In total, 11 evaluators, each with at least 10 years of experience in fields of study ranging from medicine and implementation science to computer science, participated in the output review process (ChatGPT vs human-generated output). All had familiarity or prior exposure to the original personalized automatic messaging system intervention. The evaluators rated the ChatGPT-produced outputs in terms of understandability, usability, novelty, relevance, completeness, and efficiency.
Results
Most metrics received positive scores. We identified that ChatGPT can (1) support developers to achieve high-quality products faster and (2) facilitate nontechnical communication and system understanding between technical and nontechnical team members around the development goal of rapid and easy-to-build computational solutions for medical technologies.
Conclusions
ChatGPT can serve as a usable facilitator for researchers engaging in the software development life cycle, from product conceptualization to feature identification and user story development to code generation.
Trial Registration
ClinicalTrials.gov NCT04049500; https://clinicaltrials.gov/ct2/show/NCT04049500}
}
@incollection{SHAH2017251,
title = {Chapter Seven - What Makes Everyday Scientific Reasoning So Challenging?},
editor = {Brian H. Ross},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {66},
pages = {251-299},
year = {2017},
issn = {0079-7421},
doi = {https://doi.org/10.1016/bs.plm.2016.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0079742116300214},
author = {Priti Shah and Audrey Michal and Amira Ibrahim and Rebecca Rhodes and Fernando Rodriguez},
keywords = {ANCOVA, Anecdotes, Causality bias, Decision making, Heuristic vs. analytic thinking, Science education, Scientific reasoning, Selection bias, Statistical validity},
abstract = {Informed citizens are expected to use science-based evidence to make decisions about health, behavior and public policy. To do so, they must judge whether the evidence is consistent with the claims presented (theory-evidence coordination). Unfortunately, most individuals make numerous errors in theory-evidence coordination. In this chapter, we provide an overview of research on science evidence evaluation, drawing from research in cognitive and developmental psychology, science and statistics education, decision sciences, political science and science communication. Given the breadth of this research area, we highlight some influential studies and reviews across these different topics. This body of research provides several clues about: (1) why science evidence evaluation is challenging, (2) the influence of the content and context of the evidence and (3) how the characteristics of the individual examining the evidence impact the quality of the evaluations. Finally, we suggest some possible directions for empirical research on improving evidence evaluation and point to the responsibility of scientists, especially social and behavioral scientists, in communicating their findings to the public. Overall, our goal is to give readers an interdisciplinary view of science evidence evaluation research and to integrate research from different scientific communities that address similar questions.}
}
@article{CANCHIG2025100445,
title = {Enhanced selectivity of carbon quantum dots for metal ion detection through surface modification by heteroatom doping: A study on optical properties and theoretical approach},
journal = {Carbon Trends},
volume = {18},
pages = {100445},
year = {2025},
issn = {2667-0569},
doi = {https://doi.org/10.1016/j.cartre.2024.100445},
url = {https://www.sciencedirect.com/science/article/pii/S266705692400124X},
author = {María Belén Cánchig and Floralba López and Zaillmar Morales-Navarro and Alexis Debut and Karla Vizuete and Thibault Terencio and Manuel Caetano and Juan Pablo Saucedo-Vázquez},
keywords = {Carbon quantum dots, Heteroatom-doped, Ion detection, Heavy metals},
abstract = {Water contamination by toxic metal ions has become a significant issue, requiring the development of effective ion detection methods. Traditional analytical techniques often involve toxic elements or complex devices. Carbon quantum dots (CQDs) have emerged as a promising alternative for optic ion detection due to their unique properties and compatibility with living organisms. This study focuses on synthesizing and functionalizing CQDs with various heteroatoms (N, S) to enhance their optical properties and ion selectivity. CQDs were synthesized using citric acid as the carbon source and modified with l-cysteine, ethylenediamine, and diethylenetriamine. The structural and optical properties of the CQDs were determined using several techniques, including FT-IR, TEM, UV–Vis, and Fluorescence Spectroscopy. The results indicate that doping with heteroatoms significantly alters the absorption and emission properties of CQDs. Particularly, nitrogen-doped CQDs (NCQDs) exhibited the highest absorption and emission intensities, making them ideal for sensor applications. The study also demonstrated that functionalization with sulfur could modulate emission frequencies, enhancing the detection capabilities for specific ions. Fluorescence quenching studies revealed that NCQDs and S-CQDs have a high selectivity for Hg²⁺ ions, attributed both electrostatic and covalent interactions formed between the CQDs and Hg²⁺. Computational studies supported these findings, showing that the interaction with Hg²⁺ significantly affects the energy gap of the CQDs, enhancing their sensitivity. This research contributes to the field of environmental monitoring by providing a practical solution for the detection of free metal ions in water through the development of advanced CQD-based sensors.}
}
@article{PESSOA2019158,
title = {Neural dynamics of emotion and cognition: From trajectories to underlying neural geometry},
journal = {Neural Networks},
volume = {120},
pages = {158-166},
year = {2019},
note = {special Issue in Honor of the 80th Birthday of Stephen Grossberg},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2019.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0893608019302242},
author = {Luiz Pessoa},
keywords = {Emotion, Cognition, Dynamics, Trajectories, Manifold},
abstract = {How can we study, characterize, and understand the neural underpinnings of cognitive-emotional behaviors as inherently dynamic processes? In the past 50 years, Stephen Grossberg has developed a research program that embraces the themes of dynamics, decentralized computation, emergence, selection and competition, and autonomy. The present paper discusses how these principles can be heeded by experimental scientists to advance the understanding of the brain basis of behavior. It is suggested that a profitable way forward is to focus on investigating the dynamic multivariate structure of brain data. Accordingly, central research problems involve characterizing “neural trajectories” and the associated geometry of the underlying “neural space.” Finally, it is argued that, at a time when the development of neurotechniques has reached a fever pitch, neuroscience needs to redirect its focus and invest comparable energy in the conceptual and theoretical dimensions of its research endeavor. Otherwise we run the risk of being able to measure “every atom” in the brain in a theoretical vacuum.}
}
@article{SUCHANTKE2020439,
title = {Space sustainability in Martian orbits — First insights in a technical and regulatory analysis},
journal = {Journal of Space Safety Engineering},
volume = {7},
number = {3},
pages = {439-446},
year = {2020},
note = {Space Debris: The State of Art},
issn = {2468-8967},
doi = {https://doi.org/10.1016/j.jsse.2020.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2468896720300677},
author = {Isabell Suchantke and Francesca Letizia and Vitali Braun and Holger Krag},
abstract = {Hazards from the outer space environment either natural (space weather and asteroids) or artificial (space debris and the growing number of satellites launched to orbit) pose a rising risk to space flight activities. The awareness for space sustainability and space safety has seen a continuous increase in recent years and does not stop at the Earth's sphere of influence. The first spacefaring nations start thinking about sustainability in cislunar space and the Martian environment. This work deals with the issue of space debris in Martian orbits in the light of planetary protection. A Mars Sustainability Framework has been developed. This includes a study on the orbital and regulatory environment of Mars, long-term propagation of orbits of artificial objects and the two natural moons, and the analysis of objects evolution and first approaches for collision probability computation. With this work, the issue of space debris beyond Earth orbit is analysed at an early stage.}
}
@article{FAN2020248,
title = {From Brain Science to Artificial Intelligence},
journal = {Engineering},
volume = {6},
number = {3},
pages = {248-252},
year = {2020},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2019.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S2095809920300035},
author = {Jingtao Fan and Lu Fang and Jiamin Wu and Yuchen Guo and Qionghai Dai},
keywords = {Artificial intelligence, Brain science},
abstract = {Reviewing the history of the development of artificial intelligence (AI) clearly reveals that brain science has resulted in breakthroughs in AI, such as deep learning. At present, although the developmental trend in AI and its applications has surpassed expectations, an insurmountable gap remains between AI and human intelligence. It is urgent to establish a bridge between brain science and AI research, including a link from brain science to AI, and a connection from knowing the brain to simulating the brain. The first steps toward this goal are to explore the secrets of brain science by studying new brain-imaging technology; to establish a dynamic connection diagram of the brain; and to integrate neuroscience experiments with theory, models, and statistics. Based on these steps, a new generation of AI theory and methods can be studied, and a subversive model and working mode from machine perception and learning to machine thinking and decision-making can be established. This article discusses the opportunities and challenges of adapting brain science to AI.}
}
@article{PRINSLOO2021101515,
title = {Sustainability assessment framework and methodology with trans-disciplinary numerical simulation model for analytical floatovoltaic energy system planning assessments},
journal = {Sustainable Energy Technologies and Assessments},
volume = {47},
pages = {101515},
year = {2021},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2021.101515},
url = {https://www.sciencedirect.com/science/article/pii/S2213138821005269},
author = {F.C. Prinsloo and Peter Schmitz and Andrea Lombard},
keywords = {Floatovoltaic system synthesis, WELF-nexus environmental profiling, Sustainability profiling, Floating solar simulation model, FPV sustainability assessment},
abstract = {Floatovoltaics is rapidly emerging as a novel type of sustainable energy technology, in which solar photovoltaic installations are sited directly on open-water spaces. As an agro-renewable energy-generation technology, it makes dual use of water to generate revenue from under-utilised irrigation water surfaces while also offering mutually beneficial layers of land-saving, environmental conservation and water-preservation benefits. Standardised metrics for ground-mounted photovoltaic projects, however, do not properly account for the technology’s extended range of resource-use-efficiencies and impact-effect-positives. Such knowledge gaps hinder evidence-based scientific assessments in regulatory project permissions mandated by law. Technology planning and impact assessment practices can benefit from a computer-aided technique to characterise floatovoltaic performance profiles. This paper introduces a conceptual empirical modelling framework, a holistic system dynamics-thinking methodology and a computer synthesis model to empirically predict the performance and sustainability profiles of prospective floatovoltaic installations. By inherently exploring the techno-economic and techno-environmental externalities of floatovoltaic enterprises, it translates performance profiles into sustainability indicators, articulated as WELF-nexus parameters. The paper details the integrated analytical framework, mathematical modelling formulation and digital computer synthesis model towards quantitative floatovoltaic energy system planning and sustainability assessments. The study’s main finding is that an integrated techno-enviro-economic floatovoltaic assessment methodology can be successfully modelled as a context-sensitive synthesis technique in a system dynamics modelling environment. The proposed technique can find utility in solving real-world problems with assessments in efficiency, feasibility and sustainability for agricultural floatovoltaics.}
}
@article{SHAHIM2021102345,
title = {Security of the digital transformation},
journal = {Computers & Security},
volume = {108},
pages = {102345},
year = {2021},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2021.102345},
url = {https://www.sciencedirect.com/science/article/pii/S0167404821001693},
author = {Abbas Shahim},
keywords = {Digital transformation, Digital security, Information security, Digital disruption, IT auditing},
abstract = {In the early days of computation the focus was mainly on designing, developing, maintaining, and administering infrastructures and information systems housed in data centers. To this extend, security was traditionally organized around the basic technical components (e.g. data center facilities). The point was that an associated security activity was mostly separated from a business context and in general executed by the technical staff. Security was not fully understood by other audiences because the computer terminologies were frequently used. When security elements (e.g. logical access protocols used for identification, authentication, authorization) became part of the financial statement audit, its context became clearer, and it was conducted for external auditors. However, the presented outcome of the work was not completely interpretable for these practitioners as again, it was mainly reported in Information Technology (IT) jargon, and was not linked with the financial statement either. With the emergence the Sarbanes–Oxley Act (SOX) and the fundamental role of IT in relation hereto, the context of security suddenly changed to a great extent. The audience extended as compliance, including security, became the dominating item on the agenda of many C-levels (e.g. CFOs).}
}
@incollection{BENTHEM1989331,
title = {Semantic Parallels in Natural Language and Computation},
editor = {H.-D. Ebbinghaus and J. Fernandez-Prida and M. Garrido and D. Lascar and M. Rodriquez Artalejo},
series = {Studies in Logic and the Foundations of Mathematics},
publisher = {Elsevier},
volume = {129},
pages = {331-375},
year = {1989},
booktitle = {Logic Colloquium'87},
issn = {0049-237X},
doi = {https://doi.org/10.1016/S0049-237X(08)70133-2},
url = {https://www.sciencedirect.com/science/article/pii/S0049237X08701332},
author = {Johan van Benthem},
abstract = {Publisher Summary
This chapter describes two major themes: (1) techniques for local strengthening of logical inference via minimization of models and (2) the more general dynamics of progressive handling of information in interpretation and argument. The chapter provides a coherent pattern behind some recent developments in these areas and discusses their value as affecting logic in general. The chapter also provides a mathematical analysis of the minimization operator on classes of models while also investigating several special systems in which minimal models play a central role. The chapter develops an analogy with earlier work in the philosophy of science on so-called “Ramsey eliminability” of theoretical terms in scientific theories. A technical connection is found between the general inferential properties of circumscription and more traditional conditional logic. It considers possible reductions of circumscriptive inference to standard first-order logic, establishing a high complexity for the question just when this is possible. The chapter reviews a number of results on dynamical semantics and several reductions of proposed dynamic systems to standard first-order logic. The latter system provides a promising tool for investigating dynamic modes of handling propositions.}
}
@article{MITTAL2023105092,
title = {The method of harmonic balance for the Giesekus model under oscillatory shear},
journal = {Journal of Non-Newtonian Fluid Mechanics},
volume = {321},
pages = {105092},
year = {2023},
issn = {0377-0257},
doi = {https://doi.org/10.1016/j.jnnfm.2023.105092},
url = {https://www.sciencedirect.com/science/article/pii/S0377025723001040},
author = {Shivangi Mittal and Yogesh M. Joshi and Sachin Shanbhag},
keywords = {LAOS, Spectral method, Fourier series, Numerical method},
abstract = {The method of harmonic balance (HB) is a spectrally accurate method used to obtain periodic steady state solutions to dynamical systems subjected to periodic perturbations. We adapt HB to solve for the stress response of the Giesekus model under large amplitude oscillatory shear (LAOS) deformation. HB transforms the system of differential equations to a set of nonlinear algebraic equations in the Fourier coefficients. Convergence studies find that the difference between the HB and true solutions decays exponentially with the number of harmonics (H) included in the ansatz as e−mH. The decay coefficient m decreases with increasing strain amplitude, and exhibits a “U” shaped dependence on applied frequency. The computational cost of HB increases slightly faster than linearly with H. The net result of rapid convergence and modest increase in computational cost with increasing H implies that HB outperforms the conventional method of using numerical integration to solve differential constitutive equations under oscillatory shear. Numerical experiments find that HB is simultaneously about three orders of magnitude cheaper, and several orders of magnitude more accurate than numerical integration. Thus, it offers a compelling value proposition for parameter estimation or model selection.}
}
@article{DUFVA201917,
title = {Grasping the future of the digital society},
journal = {Futures},
volume = {107},
pages = {17-28},
year = {2019},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2018.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0016328717302252},
author = {Tomi Dufva and Mikko Dufva},
keywords = {Digitalisation, Digital society, Experiential foresight, Craft education, Art education, Artistic research, Embodied learning, Critical theory},
abstract = {Society is increasingly digitalised and connected, with computers and algorithms mediating much of people’s daily activity in one way or another. The degree of digitalisation and its consequences are challenging to understand because most people lack first-hand experience of what digitalisation actually feels like. Digitalisation is abstract and difficult to grasp, which leads to a detached sense of the digital surroundings. In this paper, we argue that in order to grasp the nature and future of a digitalised society, an embodied understanding of digitalisation is needed. Such an understanding should utilise ways of knowing other than rational thinking, challenge existing narratives and move from preparing for the future to exploring novelty. We focus on the importance of a broader understanding of digitalisation within the field of education and discuss how a more diverse view is essential to empower people to take part in a digitalised society. We use the concept of ‘digi-grasping’ to analyse awareness and involvement in the digital world. By digi-grasping we mean active sense-making and existing in a world that consists of both a digital and a physical world. We argue that through ‘grasping’ the digital world it is possible to create an ethical and aesthetic attachment to society. Digi-grasping can empower people to understand and question the choices and motivations behind current digital structures and create new structures. It is thus an important approach to shaping the futures of digital society. We illustrate the concept with examples representing different modes of being and doing at the interface of the digital and physical.}
}
@incollection{MOITRA198793,
title = {Parallel Algorithms for Some Computational Problems},
editor = {Marshall C. Yovits},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {26},
pages = {93-153},
year = {1987},
booktitle = {Advances in Computers},
issn = {0065-2458},
doi = {https://doi.org/10.1016/S0065-2458(08)60006-6},
url = {https://www.sciencedirect.com/science/article/pii/S0065245808600066},
author = {Abha Moitra and S. {Sitharama Iyengar}},
abstract = {Publisher Summary
The chapter presents a survey of parallel algorithms for finding the connected and biconnected components of a graph. The chapter classifies the various parallel algorithms for finding the connected components of undirected graphs according to two major criteria: the basic technique employed and the format of the input. The basic techniques used in these algorithms are breadth-first search, transitive closure, and vertex collapse. The most common form of input is adjacency matrix. The chapter presents several parallel minimum spanning tree algorithms for different types of parallel computational models. A minimum spanning tree of a weighted, connected, and undirected graph is defined as a set of edges of the graph that connects all vertices and whose total edge weight is minimum. The chapter discusses various other parallel graph algorithms for shortest path, maximum matching, planarity testing, and maximal independent set. It describes parallel algorithms for various nongraph-theoretic problems like arithmetic expression and polynomial evaluation, string matching, tree balancing, and alpha-beta search.}
}
@article{MUSTAPHA2025103066,
title = {A survey of emerging applications of large language models for problems in mechanics, product design, and manufacturing},
journal = {Advanced Engineering Informatics},
volume = {64},
pages = {103066},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.103066},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624007171},
author = {K.B. Mustapha},
keywords = {Pre-trained language models, Large language models, Generative AI, Generative pre-trained transformer, Mechanical engineering, Engineering design, Manufacturing, Mechanics, Intelligent digital twins, Intelligent maintenance, Creativity},
abstract = {In the span of three years, the application of large language models (LLMs) has accelerated across a multitude of professional sectors. Amid this development, a new collection of studies has manifested around leveraging LLMs for segments of the mechanical engineering (ME) field. Concurrently, it has become clear that general-purpose LLMs faced hurdles when deployed in this domain, partly due to their training on discipline-agnostic data. Accordingly, there is a recent uptick of derivative ME-specific LLMs being reported. As the research community shifts towards these new LLM-centric solutions for ME-related problems, the shift compels a deeper look at the diffusion of LLMs in this emerging landscape. Consequently, this review consolidates the diversity of ME-tailored LLMs use cases and identifies the supportive technical stacks associated with these implementations. Broadly, the review demonstrates how various categories of LLMs are re-shaping concrete aspects of engineering design, manufacturing and applied mechanics. At a more specific level, it uncovered emerging LLMs’ role in boosting the intelligence of digital twins, enriching bidirectional communication within the human-cyber-physical infrastructure, advancing the development of intelligent process planning in manufacturing and facilitating inverse mechanics. It further spotlights the coupling of LLMs with other generative models for promoting efficient computer-aided conceptual design, prototyping, knowledge discovery and creativity. Finally, it revealed training modalities/infrastructures necessary for developing ME-specific language models, discussed LLMs' features that are incongruent with typical engineering workflows, and concluded with prescriptive approaches to mitigate impediments to the progressive adoption of LLMs as part of advanced intelligent solutions.}
}
@article{DUAL2024596,
title = {The Future of Durable Mechanical Circulatory Support: Emerging Technological Innovations and Considerations to Enable Evolution of the Field},
journal = {Journal of Cardiac Failure},
volume = {30},
number = {4},
pages = {596-609},
year = {2024},
issn = {1071-9164},
doi = {https://doi.org/10.1016/j.cardfail.2024.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S1071916424000411},
author = {Seraina A. Dual and Jennifer Cowger and Ellen Roche and Aditi Nayak},
keywords = {Mechanical circulatory support, left ventricular assist device, translation, innovation},
abstract = {The field of durable mechanical circulatory support (MCS) has undergone an incredible evolution over the past few decades, resulting in significant improvements in longevity and quality of life for patients with advanced heart failure. Despite these successes, substantial opportunities for further improvements remain, including in pump design and ancillary technology, perioperative and postoperative management, and the overall patient experience. Ideally, durable MCS devices would be fully implantable, automatically controlled, and minimize the need for anticoagulation. Reliable and long-term total artificial hearts for biventricular support would be available; and surgical, perioperative, and postoperative management would be informed by the individual patient phenotype along with computational simulations. In this review, we summarize emerging technological innovations in these areas, focusing primarily on innovations in late preclinical or early clinical phases of study. We highlight important considerations that the MCS community of clinicians, engineers, industry partners, and venture capital investors should consider to sustain the evolution of the field.}
}
@incollection{ADDIS2025501,
title = {Memory and imagination},
editor = {Jordan Henry Grafman},
booktitle = {Encyclopedia of the Human Brain (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {501-513},
year = {2025},
isbn = {978-0-12-820481-8},
doi = {https://doi.org/10.1016/B978-0-12-820480-1.00135-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128204801001352},
author = {Donna Rose Addis},
keywords = {Associative, Autobiographical memory, Default mode network, Episodic memory, Frontoparietal control network, Future thinking, Hippocampus, Imagination, Medial prefrontal cortex, Prospection, Relational processing, Schema, Simulation},
abstract = {The human brain has a remarkable capacity to not only remember events from the past but to construct a variety of imagined experiences, ranging from hypothetical and counterfactual past events, to future events and entirely fictional episodes. Both remembering and imagining is underpinned by the brain's simulation system: default mode network. I describe the theoretical beginnings of this relatively new topic in contemporary neuroscience, as well as neuroimaging investigations of autobiographical memory and prospective imagination that together provide evidence of a single “simulation system” supported primarily by core functions of the default mode network: associating elements, associative schematic processes, and buffering the emergent simulation.}
}
@article{SHIEH1993421,
title = {Massively parallel computational methods for finite element analysis of transient structural responses},
journal = {Computing Systems in Engineering},
volume = {4},
number = {4},
pages = {421-433},
year = {1993},
note = {Parallel Computational Methods for Large-Scale Structural Analysis and Design},
issn = {0956-0521},
doi = {https://doi.org/10.1016/0956-0521(93)90011-K},
url = {https://www.sciencedirect.com/science/article/pii/095605219390011K},
author = {R.C. Shieh},
abstract = {With the emphasis on the finitely damped system (e.g. control structure interaction) case, two fully implicit and two semi-implicit sets of finite element method-based numerical algorithms are formulated for transient response analysis of space frame and truss structures in a massively parallel processing (MPP) environment. All algorithm sets use an implicit force calculation/vector equation of motion assembly procedure. The semi-implicit algorithms are based on the explicit central difference (CD) and the fourth-order Runge-Kutta (RK4) schemes, respectively, in conjunction with the use of mass lumping techniques so that solution of the recurrence equations for unknown displacements is reduced to a trivial diagonal matrix inversion operation. The fully implicit algorithm sets are based on the Newmark Beta (NB) and CD schemes, respectively, in conjunction with use of the (iterative) preconditioned conjugate gradient (PCG) method for solving the linear algebraic recurrence equations. The semi-implicit algorithm sets are fully implemented and assessed on an MPP CM-2 computer. A preliminary assessment of the fully implicit sets of algorithms is made on a Sun Workstation. These numerical study results show that the newly formulated MPP algorithms are, to a varying degree, superefficient (or potentially superefficient) on the CM-2 compared with, and even highly competitive against, the conventional sequential algorithms on an advanced serial computer.}
}
@article{RIZZOLATTI1997562,
title = {Parietal cortex: from sight to action},
journal = {Current Opinion in Neurobiology},
volume = {7},
number = {4},
pages = {562-567},
year = {1997},
issn = {0959-4388},
doi = {https://doi.org/10.1016/S0959-4388(97)80037-2},
url = {https://www.sciencedirect.com/science/article/pii/S0959438897800372},
author = {Giacomo Rizzolatti and Leonardo Fogassi and Vittorio Gallese},
abstract = {Recent findings have altered radically our thinking about the functional role of the parietal cortex. According to this view, the parietal lobe consists of a multiplicity of areas with specific connections to the frontal lobe. These areas, together with the frontal areas to which they are connected, mediate distinct sensorimotor transformations related to the control of hand, arm, eye or head movements. Space perception is not unitary, but derives from the joint activity of the fronto-parietal circuits that control actions requiring space computation.}
}
@article{BOGGS19831,
title = {The integration of structure determination by computation, electron diffraction and microwave spectroscopy},
journal = {Journal of Molecular Structure},
volume = {97},
pages = {1-16},
year = {1983},
note = {Determination of Molecular Structure by Microwave Spectroscopy and Electron Diffraction},
issn = {0022-2860},
doi = {https://doi.org/10.1016/0022-2860(83)90171-0},
url = {https://www.sciencedirect.com/science/article/pii/0022286083901710},
author = {James E. Boggs},
abstract = {The history of the interaction between experimental structure determinations by microwave spectroscopy and by gas phase electron diffraction is briefly reviewed in terms of three eras: (1) competition and antagonism, (2) comparison and correction, and (3) integration of analysis. A similar progression is noted for the relation between experimental and theoretical methods for studying molecular structure, with the present time straddling ages (2) and (3). Examples are given from a variety of studies involving various degrees of methodological interaction. The true integration of experimental and computational structural studies is still in its infancy with the primary illustrations involving the evaluation of theoretical structural offset values from experimental evidence, the transfer of theoretically determined parameters into the fitting of experimental data, and the current development of methods for utilizing vibrational information obtained from the combined analysis of computed theoretical and experimental infrared data in the further analysis of experimental diffraction and microwave information.}
}
@article{KHEDMATIMORASAE2024219,
title = {Advancing the discourse: A next-generation value chain-based taxonomy for circular economy key performance indicators},
journal = {Sustainable Production and Consumption},
volume = {48},
pages = {219-234},
year = {2024},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2024.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S2352550924001428},
author = {Esmaeil Khedmati-Morasae and Markus Zils and Peter Hopkinson and Ryan Nolan and Fiona Charnley and Okechukwu Okorie and Halid Abu-Bakar},
keywords = {Circular economy, Key performance indicators, Taxonomy, Value chain, Systemic},
abstract = {The growth of interest in circular economy (CE) has been accompanied by different approaches to measurement of CE outcomes and impacts, leading to a wide portfolio of indicators with varying degrees of overlap, inconsistency, and convergence. The aim of this paper is to propose a unifying framework for CE indicators, as the next generation of CE taxonomies. We first undertake a scoping review of 59 review papers on CE indicators using manual and computational methods (i.e., topic modelling) to inform the taxonomy structure and content. As a result, we report on 11 clusters of approaches that have been attentive to different dimensions of CE (e.g. horizontal value chain, vertical scale of operation (macro, meso, micro), impact category (economic, biophysical, social), material vs product focus, etc.). Highlighting the strengths and weakness of these approaches, we identify gaps in dimensions related to horizontal and vertical scales of measurement, and propose an agnostic, integrative framework that builds on the scientific foundations of previous research, within a more systemic and comprehensive taxonomy. This taxonomy could be used as a guiding framework or heuristic for regulators, both nationally and internationally, and for practitioners to undertake a comprehensive measurement and assessment of CE related interventions and initiatives at scale.}
}
@article{LAL2023100791,
title = {IOT-based cyber security identification model through machine learning technique},
journal = {Measurement: Sensors},
volume = {27},
pages = {100791},
year = {2023},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2023.100791},
url = {https://www.sciencedirect.com/science/article/pii/S2665917423001277},
author = {Bechoo Lal and S. Ravichandran and R. Kavin and N. {Anil Kumar} and Dibyahash Bordoloi and R. {Ganesh Kumar}},
keywords = {Cyber security, Machine learning algorithms, Security, Repositories, Meta-classifier methods, Internet of things},
abstract = {Manual vulnerability evaluation tools produce erroneous data and lead to difficult analytical thinking. Such security concerns are exacerbated by the variety, imperfection, and redundancies of modern security repositories. These problems were common traits of producers and public vulnerability disclosures, which make it more difficult to identify security flaws through direct analysis through the Internet of Things (IoT). Recent breakthroughs in Machine Learning (ML) methods promise new solutions to each of these infamous diversification and asymmetric information problems throughout the constantly increasing vulnerability reporting databases. Due to their varied methodologies, those procedures themselves display varying levels of performance. The authors provide a method for cognitive cybersecurity that enhances human cognitive capacity in two ways. To create trustworthy data sets, initially reconcile competing vulnerability reports and then pre-process advanced embedded indicators. This proposed methodology's full potential has yet to be fulfilled, both in terms of its execution and its significance for security evaluation in application software. The study shows that the recommended mental security methodology works better when addressing the above inadequacies and the constraints of variation among cybersecurity alert mechanisms. Intriguing trade-offs are presented by the experimental analysis of our program, in particular the ensemble method that detects tendencies of computational security defects on data sources.}
}
@article{FITZPATRICK2020101942,
title = {The relation between academic abilities and performance in realistic word problems},
journal = {Learning and Individual Differences},
volume = {83-84},
pages = {101942},
year = {2020},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2020.101942},
url = {https://www.sciencedirect.com/science/article/pii/S1041608020301229},
author = {Cheryll L. Fitzpatrick and Darcy Hallett and Kyle R. Morrissey and Nadine R. Yıldız and Rutanya Wynes and Felix Ayesu},
keywords = {Word problems, Academic abilities, Educational psychology, Math cognition},
abstract = {The research on realistic word problems investigates how children (and even adults) largely fail to incorporate real-world knowledge into mathematical word problems. Because of this, most research in this area focuses on improving realistic thinking. However, very little research has explored what other abilities might predict which children actually do take real-world information into account, and what this might imply about the nature of realistic responding. We tested whether general academic abilities, such as verbal skill, reading comprehension, and math calculation skill, previously shown to be related to standard word problem performance, are related to realistic responses, and whether realistic responding is related to standard word problem solving. In our sample of sixth-grade students, only reading comprehension was independently predictive of solving realistic word problems. Performance on realistic word problems, however, was independently predictive of solving standard word problems. As such, realistic word problems may reflect problem solving ability independent of general academic ability, and therefore may be an ability worth fostering.}
}
@article{QU2024102255,
title = {Unmanned combat aerial vehicle path planning in complex environment using multi-strategy sparrow search algorithm with double-layer coding},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {10},
pages = {102255},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102255},
url = {https://www.sciencedirect.com/science/article/pii/S1319157824003446},
author = {Liangdong Qu and Jingkun Fan},
keywords = {UCAV path planning, Double-layer coding, Complex environment, Sparrow search algorithm, Dynamic fitness regulation learning strategy},
abstract = {Unmanned combat aerial vehicles (UCAV) path planning in complex environments demands a substantial number of path points to determine feasible paths. Establishing an effective flight path for UCAVs requires numerous path points to account for fuel constraints, artillery threats, and radar avoidance. This increase in path points raises the dimensionality of the problem, which in turn degrades algorithm performance. To mitigate this issue, a double-layer coding (DLC) model is utilized to remove redundant path points, consequently lowering computational complexity and operational difficulties. Meanwhile, this paper introduces a novel enhanced sparrow search algorithm (MESSA) based on multi-strategy for UCAV path planning. The MESSA incorporates a novel dynamic fitness regulation learning strategy (DFRL), a random differential learning strategy (RDL), an elite example equilibrium learning strategy (EEEL), a dynamic elimination and regeneration strategy based on the elite example (DERE), and quadratic interpolation (QI). Furthermore, MESSA is compared against 11 state-of-the-art algorithms, demonstrating exceptional optimization performance and robustness. Additionally, the combination of MESSA with the DLC model (DLC-MESSA) is applied to solve the UCAV path planning problem. The experimental results from five complex environments indicate that DLC-MESSA outperforms other algorithms in 80% of the cases by achieving the lowest average cost, thereby demonstrating its superior robustness and computational efficiency.}
}
@article{GRIFFEN20208695,
title = {Chemists: AI Is Here; Unite To Get the Benefits},
journal = {Journal of Medicinal Chemistry},
volume = {63},
number = {16},
pages = {8695-8704},
year = {2020},
issn = {1520-4804},
doi = {https://doi.org/10.1021/acs.jmedchem.0c00163},
url = {https://www.sciencedirect.com/science/article/pii/S1520480420001672},
author = {Edward J. Griffen and Alexander G. Dossetter and Andrew G. Leach},
abstract = {The latest developments in artificial intelligence (AI) have arrived into an existing state of creative tension between computational and medicinal chemists. At their most productive, medicinal and computational chemists have made significant progress in delivering new therapeutic agents into the clinic. However, the relationship between these communities has the prospect of being weakened by application of oversimplistic AI methods that, if they fail to deliver, will reinforce unproductive prejudices. We review what can be learned from our history of integrating QSAR and structure-based methods into drug discovery. Now with synthesis and testing available as contract services, the environment for computational innovation has changed and we consider the impact this may have on the relationships in our disciplines. We discuss the current state of interdisciplinary communication and suggest approaches to bring the subdisciplines together in order to improve computational medicinal chemistry and, most importantly, deliver better medicines to the clinic faster.
}
}
@article{GINEITYTE1999205,
title = {On the future of the Hückel model},
journal = {Journal of Molecular Structure: THEOCHEM},
volume = {491},
number = {1},
pages = {205-209},
year = {1999},
issn = {0166-1280},
doi = {https://doi.org/10.1016/S0166-1280(99)00116-5},
url = {https://www.sciencedirect.com/science/article/pii/S0166128099001165},
author = {V. Gineityte},
keywords = {Basis orbitals, Hückel model, Hamiltonian matrix},
abstract = {In an attempt to foresee the prospects of the qualitative trend in quantum chemistry, the place of the Hückel model is analyzed in the broad context of quantum mechanical and chemical perspectives on the molecular world. Quantum mechanics and chemistry are considered as complementary approaches to molecular structure and properties that are irreducible one to another. Arguments are given for the hypothesis that the Hückel model makes a separate level of investigation of molecules situated in between quantum mechanics and chemistry. In this context, the need is emphasized for development of new concepts immanent in the very Hückel model. These concepts are anticipated to play the role of terms for qualitative orbital thinking, the persistent need for which was emphasized recently (R. Hoffmann, J. Mol. Struct. (Theochem), 424 (1998) 1).}
}
@article{FROWNFELTERLOHRKE201768,
title = {Teaching good Excel design and skills: A three spreadsheet assignment project},
journal = {Journal of Accounting Education},
volume = {39},
pages = {68-83},
year = {2017},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2016.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0748575115300403},
author = {Cynthia {Frownfelter- Lohrke}},
keywords = {Excel, Spreadsheets, Spreadsheet design, Active learning, Project-based learning},
abstract = {Over sixty percent of AIS courses cover Excel because it is an important tool for accounting students to learn and master. Although spreadsheet programs like Excel provide powerful analytical tools for business, in practice, they are often created and used by people with minimal programming experience. Consequently, users can often develop spreadsheets containing critical errors, which, in turn, can cause significant losses for their businesses. Errors can be reduced, however, by learning and employing good spreadsheet design techniques. Good spreadsheet design also makes it easier to update and continue to use a spreadsheet over time. This paper describes a method for teaching spreadsheet design where students complete three spreadsheet assignments in an iterative and repetitive process. By the time students have completed these assignments, they will have acquired good spreadsheet design skills and improved their basic Excel skills.}
}
@article{ZHAO2013278,
title = {An intelligent chiller fault detection and diagnosis methodology using Bayesian belief network},
journal = {Energy and Buildings},
volume = {57},
pages = {278-288},
year = {2013},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2012.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0378778812005968},
author = {Yang Zhao and Fu Xiao and Shengwei Wang},
keywords = {Fault detection, Fault diagnosis, Centrifugal chiller, Bayesian network},
abstract = {A generic intelligent fault detection and diagnosis (FDD) strategy is proposed in this study to simulate the actual diagnostic thinking of chiller experts. A three-layer Diagnostic Bayesian Network (DBN) is developed to diagnose chiller faults based on the Bayesian Belief Network (BBN) theory. The structure of the DBN is a graphical and qualitative illustration of the intrinsic causal relationships among causal factors in Layer 1, faults in Layer 2 and fault symptoms in Layer 3. The parameters of the DBN represent the quantitative probabilistic relationships among the three layers. To diagnose chiller faults, posterior probabilities of the faults under observed evidences are calculated based on the probability analysis and the graph theory. Compared with other FDD strategies, the proposed strategy can make use of more useful information of the chiller concerned and expert knowledge. It is effective and efficient in diagnosing faults based on uncertain, incomplete and conflicting information. Evaluation of the strategy was made on a 90-ton water-cooled centrifugal chiller reported in ASHRAE RP-1043.}
}
@article{LOWRIE20112244,
title = {Gender differences in students’ mathematics game playing},
journal = {Computers & Education},
volume = {57},
number = {4},
pages = {2244-2248},
year = {2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511001394},
author = {Tom Lowrie and Robyn Jorgensen},
keywords = {Gender studies, Elementary education, Pedagogical issues, Numeracy practices},
abstract = {The investigation monitored the digital game-playing behaviours of 428 primary-aged students (aged 10–12 years). Chi-square analysis revealed that boys tend to spend more time playing digital games than girls while boys and girls play quite different game genres. Subsequent analysis revealed statistically significant gender differences in terms of the types of mathematics-rich games students prefer to play. Girls preferred to play games that required problem solving, quantitative computations and the interpretation of graphs. Boys preferred games that required visual/spatial engagement. Given the fact that boys outperform girls on spatial tasks and mathematics assessment items that contain graphics, this study has implications for the development of students' mathematics sense making.}
}
@article{BARRON1992245,
title = {A bibliography on computational molecular biology and genetics},
journal = {Mathematical and Computer Modelling},
volume = {16},
number = {6},
pages = {245-319},
year = {1992},
issn = {0895-7177},
doi = {https://doi.org/10.1016/0895-7177(92)90166-I},
url = {https://www.sciencedirect.com/science/article/pii/089571779290166I},
author = {Sarah Barron and Matthew Witten and Gongxian Liu},
abstract = {The field of computational molecular biology and genetics is expanding at an enormous rate. Journals such as CABIOS and Nucleic Acids Research routinely publish articles on computational and mathematical aspects of biology. The purpose of this paper is to provide a bibliographic review of the literature in this area related to DNA mapping and sequence analysis. We have focused on computer and mathematical aspects of molecular biology and genetics (interpreted in a broad sense). Authors are solicited for their additions/corrections to this bibliography. Contact us at the above address.}
}
@article{NAKAMURA20091639,
title = {A shift of mind – Introducing a concept creation model},
journal = {Information Sciences},
volume = {179},
number = {11},
pages = {1639-1646},
year = {2009},
note = {Including Special Issue on Chance Discovery},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2008.11.036},
url = {https://www.sciencedirect.com/science/article/pii/S0020025508004933},
author = {Jun Nakamura and Yukio Ohsawa},
keywords = {Creativity, Concept, Ambiguity and constraint},
abstract = {The ability to construct concepts is indispensable to both individual and evolutionary development. Our model involves the use of ambiguous stimuli to facilitate decision-making by promoting analogical reasoning. Toward this end, we have developed Web-based exercises in word categorization for the purpose of engaging participants in analogical reasoning that contributes to the integration of words and leads to the construction of new concepts. 12 graduate students and 20 junior high school students were presented with ambiguous information for the purpose of comparison between the senior and the junior students. We hypothesized that the senior students tend to behave with more insight rather than junior students with less activation of thought process. Our results suggested that the presentation of the ambiguous stimuli were associated with unique thought processes, which are consistent with approaches to word categorization that reflect either the experience of insight or the operation of a trial and error strategy, depending on the junior or the senior students. We showed that the senior students tend to be more like insight into categorization design, while the junior as rather try and error behavior, in consideration of needed time and actions in analogical thinking.}
}
@article{LEIVANT198651,
title = {Typing and computational properties of lambda expressions},
journal = {Theoretical Computer Science},
volume = {44},
pages = {51-68},
year = {1986},
issn = {0304-3975},
doi = {https://doi.org/10.1016/0304-3975(86)90109-X},
url = {https://www.sciencedirect.com/science/article/pii/030439758690109X},
author = {Daniel Leivant},
abstract = {We use a perception of second-order typing in the λ-Calculus, as conveying semantic properties of expressions in models over λ-expressions, to exhibit natural and uniform proofs of theorems of Girard (1971/1972) and of Coppo, Dezani and Veneri (1981) about the relations between typing properties and computational properties of λ-expressions (solvability, normalizability, strong normalizability), and of some generalizations of these theorems.}
}
@article{BOEING2021102013,
title = {Spatial information and the legibility of urban form: Big data in urban morphology},
journal = {International Journal of Information Management},
volume = {56},
pages = {102013},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2019.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0268401219302154},
author = {Geoff Boeing},
keywords = {OpenStreetMap, Urban design, Urban form, Urban morphology, Urban planning, Visualization},
abstract = {Urban planning and morphology have relied on analytical cartography and visual communication tools for centuries to illustrate spatial patterns, conceptualize proposed designs, compare alternatives, and engage the public. Classic urban form visualizations – from Giambattista Nolli’s ichnographic maps of Rome to Allan Jacobs’s figure-ground diagrams of city streets – have compressed physical urban complexity into easily comprehensible information artifacts. Today we can enhance these traditional workflows through the Smart Cities paradigm of understanding cities via user-generated content and harvested data in an information management context. New spatial technology platforms and big data offer new lenses to understand, evaluate, monitor, and manage urban form and evolution. This paper builds on the theoretical framework of visual cultures in urban planning and morphology to introduce and situate computational data science processes for exploring urban fabric patterns and spatial order. It demonstrates these workflows with OSMnx and data from OpenStreetMap, a collaborative spatial information system and mapping platform, to examine street network patterns, orientations, and configurations in different study sites around the world, considering what these reveal about the urban fabric. The age of ubiquitous urban data and computational toolkits opens up a new era of worldwide urban form analysis from integrated quantitative and qualitative perspectives.}
}
@article{JI2023106379,
title = {Scalable incomplete multi-view clustering via tensor Schatten p-norm and tensorized bipartite graph},
journal = {Engineering Applications of Artificial Intelligence},
volume = {123},
pages = {106379},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.106379},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623005638},
author = {Guangyan Ji and Gui-Fu Lu and Bing Cai},
keywords = {Scalable incomplete multi-view clustering, Tensorized bipartite graph, Graph completion, Tensor low-rank constraint},
abstract = {Graph-based incomplete multi-view clustering (IMVC) methods have drawn considerable attention due to their good performance in exploring the nonlinear structure of data. However, they still have the following shortcomings. First, graph construction and eigen decomposition of the Laplacian matrix included in the IMVC methods generally have high computational complexity. Second, most methods do not consider the impact of missing views and neglect the potential relationships between different views. Third, few algorithms consider both intra-view and inter-view information for clustering. Therefore, we innovatively propose a scalable incomplete multi-view clustering via the tensor Schatten p-norm and tensorized bipartite graph (SIMVC/TSTBG) method, which combines tensorized bipartite graph, graph completion, and tensor low-rank constraint into a joint framework. Concretely, we first construct bipartite graphs based on the selected m anchor points and the n data points, reducing the size of the graph from n×n to n×m(m<<n), which considerably reduces the computational complexity. Second, we adaptively complete the missing bipartite graph, which reduces the effect of missing view information on the clustering results. Third, to explore connections between missing views and mine high-order information between views, we splice the bipartite graphs into a tensor and impose a tensor low-rank constraint, i.e., the tensor Schatten p-norm, on it. At the same time, we also design an efficient algorithm to solve SIMVC/TSTBG. To our knowledge, we are the first successful practice to integrate the tensor technique with the scalable IMVC method. Compared with other IMVC methods, the results on seven datasets fully show the high efficiency and effectiveness of SIMVC/TSTBG.}
}
@article{HALL198939,
title = {Computational approaches to analogical reasoning: A comparative analysis},
journal = {Artificial Intelligence},
volume = {39},
number = {1},
pages = {39-120},
year = {1989},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(89)90003-9},
url = {https://www.sciencedirect.com/science/article/pii/0004370289900039},
author = {Rogers P. Hall},
abstract = {Analogical reasoning has a long history in artificial intelligence research, primarily because of its promise for the acquisition and effective use of knowledge. Defined as a representational mapping from a known “source” domain into a novel “target” domain, analogy provides a basic mechanism for effectively connecting a reasoner's past and present experience. Using a four-component process model of analogical reasoning, this paper reviews sixteen computational studies of analogy. These studies are organized chronologically within broadly defined task domains of automated deduction, problem solving and planning, natural language comprehension, and machine learning. Drawing on these detailed reviews, a comparative analysis of diverse contributions to basic analogy processes identifies recurrent problems for studies of analogy and common approaches to their solution. The paper concludes by arguing that computational studies of analogy are in a state of adolescence: looking to more mature research areas in artificial intelligence for robust accounts of basic reasoning processes and drawing upon a long tradition of research in other disciplines.}
}
@article{GERSTENBERG2024924,
title = {Counterfactual simulation in causal cognition},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {10},
pages = {924-936},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324001074},
author = {Tobias Gerstenberg},
keywords = {counterfactuals, causality, mental simulation, intuitive physics, theory of mind},
abstract = {How do people make causal judgments and assign responsibility? In this review article, I argue that counterfactual simulations are key. To simulate counterfactuals, we need three ingredients: a generative mental model of the world, the ability to perform interventions on that model, and the capacity to simulate the consequences of these interventions. The counterfactual simulation model (CSM) uses these ingredients to capture people’s intuitive understanding of the physical and social world. In the physical domain, the CSM predicts people’s causal judgments about dynamic collision events, complex situations that involve multiple causes, omissions as causes, and causes that sustain physical stability. In the social domain, the CSM predicts responsibility judgments in helping and hindering scenarios.}
}
@article{YANG201616,
title = {The future nexus of the Brahmaputra River Basin: Climate, water, energy and food trajectories},
journal = {Global Environmental Change},
volume = {37},
pages = {16-30},
year = {2016},
issn = {0959-3780},
doi = {https://doi.org/10.1016/j.gloenvcha.2016.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0959378016300036},
author = {Y.C. Ethan Yang and Sungwook Wi and Patrick A. Ray and Casey M. Brown and Abedalrazq F. Khalil},
keywords = {The Yarlung Tsangpo River, The Jamuna River, Water resources systems analysis, Transboundary water management, Ex post scenario analysis},
abstract = {Advance knowledge of conflicting trajectories of water–energy–food (WEF) nexus is highly relevant for water policy and planning, especially for basins that cross national boundaries. The Brahmaputra River Basin in South Asia, home for 130 million people, is such a basin. Development of new hydropower projects, upstream water diversions and possible climate changes introduce concerns among riparian countries about future water supply for energy and food production in the basin. This study presents a new hydro-economic water system model of the basin coupled with ex post scenario analysis under the “nexus thinking” concept to identify and illustrate where development paths are in conflict. Results indicate that the ability of future development to remain free of conflict hinges mostly on the amount of precipitation falling in the basin in the future. Uncertain future precipitation along with uncertain future temperature and the unknown amount of upstream water diversion combine to strongly influence future water, energy and food production in the basin. Specifically, decreases in precipitation coupled with large upstream diversions (e.g., diversion in the territory of China) would leave one or more riparian countries unable to secure enough water to produce their desired energy and food. Future climate projected by General Circulation Models suggest a warmer and wetter climate condition in the region, which is associated with an increase in streamflow and easing of conflicts at the WEF nexus in the basin. The methodology presented here is expected to be generally useful for diagnosing the conditions that may cause water resources development goals to not be achieved due to either changes in climate or water use among competing users.}
}
@article{TAYLOR1999943,
title = {Towards the networks of the brain: from brain imaging to consciousness},
journal = {Neural Networks},
volume = {12},
number = {7},
pages = {943-959},
year = {1999},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(99)00044-1},
url = {https://www.sciencedirect.com/science/article/pii/S0893608099000441},
author = {J.G. Taylor},
keywords = {Brain imaging, Consciousness, Structural modelling, Motion after-effect, Planning, Thinking, Self},
abstract = {The manner in which the brain computes in various tasks is being probed at a deep level by modern brain imaging techniques, with an increasing appreciation of the different networks being used to solve these tasks. There is simultaneously developing a neural modelling technology, which attempts to explain the underlying computations being performed by this set of networks. This paper describes results from brain imaging and how they may be related to the underlying neural networks by means of structural modelling. It thereby attempts to give an initial glimpse of the emerging picture of the functionality of brain networks. It concludes with a discussion of the role of consciousness in global processing, and how particular styles of neural processing can attain this.}
}
@article{ALQARALLEH20223913,
title = {Automated Handwriting Recognition and Speech Synthesizer for Indigenous Language Processing},
journal = {Computers, Materials and Continua},
volume = {72},
number = {2},
pages = {3913-3927},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.026531},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822014461},
author = {Bassam A. Y. Alqaralleh and Fahad Aldhaban and Feras Mohammed A-Matarneh and Esam A. AlQaralleh},
keywords = {Computational linguistics, handwriting character recognition, natural language processing, indigenous language},
abstract = {In recent years, researchers in handwriting recognition analysis relating to indigenous languages have gained significant internet among research communities. The recent developments of artificial intelligence (AI), natural language processing (NLP), and computational linguistics (CL) find useful in the analysis of regional low resource languages. Automatic lexical task participation might be elaborated to various applications in the NLP. It is apparent from the availability of effective machine recognition models and open access handwritten databases. Arabic language is a commonly spoken Semitic language, and it is written with the cursive Arabic alphabet from right to left. Arabic handwritten Character Recognition (HCR) is a crucial process in optical character recognition. In this view, this paper presents effective Computational linguistics with Deep Learning based Handwriting Recognition and Speech Synthesizer (CLDL-THRSS) for Indigenous Language. The presented CLDL-THRSS model involves two stages of operations namely automated handwriting recognition and speech recognition. Firstly, the automated handwriting recognition procedure involves preprocessing, segmentation, feature extraction, and classification. Also, the Capsule Network (CapsNet) based feature extractor is employed for the recognition of handwritten Arabic characters. For optimal hyperparameter tuning, the cuckoo search (CS) optimization technique was included to tune the parameters of the CapsNet method. Besides, deep neural network with hidden Markov model (DNN-HMM) model is employed for the automatic speech synthesizer. To validate the effective performance of the proposed CLDL-THRSS model, a detailed experimental validation process takes place and investigates the outcomes interms of different measures. The experimental outcomes denoted that the CLDL-THRSS technique has demonstrated the compared methods.}
}
@article{PAVLOVA2025103832,
title = {A developmental perspective on mind wandering and its relation to goal-directed thought},
journal = {Consciousness and Cognition},
volume = {129},
pages = {103832},
year = {2025},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2025.103832},
url = {https://www.sciencedirect.com/science/article/pii/S105381002500025X},
author = {Maria K. Pavlova},
keywords = {Attention development, Direct memory retrieval, Executive control development, Motivated attention, Spontaneous thought, Stimulus-independent thought, Task-unrelated thought},
abstract = {Mind wandering (i.e., thoughts drifting from one topic to another, with no immediate connection to the perceptual field or the ongoing task) is a widespread cognitive phenomenon. There has been increasing research interest in mind wandering in children and adolescents. However, the developmental origins of this phenomenon remain largely unknown. In the present article, I summarize the purported cognitive mechanisms of mind wandering in adults and review the empirical findings on mind wandering and automatic memory retrieval in children and adolescents. I propose a comprehensive account of the emergence of mind wandering in early and middle childhood, covering the development of its central components identified in the adult literature: motivational and emotional processes, episodic and semantic processes, perceptual decoupling, and meta-awareness. Paying special attention to the roles of developing motivation and executive control, I then address the relationship between mind wandering and goal-directed thought in children.}
}
@article{LEUKHIN2018300,
title = {Bio-plausible simulation of three monoamine systems to replicate emotional phenomena in a machine},
journal = {Procedia Computer Science},
volume = {145},
pages = {300-305},
year = {2018},
note = {Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.11.075},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918323639},
author = {Alexey Leukhin and Max Talanov and Jordi Vallverdú and Fail Gafarov},
keywords = {affective computing, affective computation, spiking neural networks, bio-inspired cognitive architecture},
abstract = {In this paper we present the validation of the three-dimensional model of emotions by Hugo Lövheim the “cube of emotion” via neurosimulation in the NEST. We also present the extension of original “cube of emotion” with the bridge to computational processes parameters. The neurosimulation is done via re-implementation of dopamine (DA), serotonin (5-HT) and noradrenaline (NA) subsystems of a rat brain to replicate 8 basic psycho-emotional states according to the “cube of emotion”. Results of neu-rosimulations indicate the incremental influence of DA and NA over computational resources of a psycho-emotional state while 5-HT decreases the computational resources used to calculate a psycho-emotional state. This way we indicate the feasibility of the bio-plausible re-implementation of psycho-emotional states in a computational system. This approach could be useful extension of decision making and load balancing components of modern artificial agents as well as intelligent robotic systems.}
}
@article{SALAHSHOORI2024123888,
title = {Simulation-based approaches for drug delivery systems: Navigating advancements, opportunities, and challenges},
journal = {Journal of Molecular Liquids},
volume = {395},
pages = {123888},
year = {2024},
issn = {0167-7322},
doi = {https://doi.org/10.1016/j.molliq.2023.123888},
url = {https://www.sciencedirect.com/science/article/pii/S0167732223026958},
author = {Iman Salahshoori and Mahdi Golriz and Marcos A.L. Nobre and Shahla Mahdavi and Rahime {Eshaghi Malekshah} and Afsaneh Javdani-Mallak and Majid {Namayandeh Jorabchi} and Hossein {Ali Khonakdar} and Qilin Wang and Amir H. Mohammadi and Seyedeh {Masoomeh Sadat Mirnezami} and Farshad Kargaran},
keywords = {Computational fluid dynamics, Drug delivery systems, Molecular simulations, Optimization, Molecular dynamics simulation, Monte Carlo simulation},
abstract = {Efficient drug delivery systems (DDSs) play a pivotal role in ensuring pharmaceuticals’ targeted and effective administration. However, the intricate interplay between drug formulations and delivery systems poses challenges in their design and optimization. Simulations have emerged as indispensable tools for comprehending these interactions and enhancing DDSs performance to address this complexity. This comprehensive review explores the latest advancements in simulation techniques for DDSs and provides a detailed analysis. The review encompasses various simulation methodologies, including molecular dynamics (MD), Monte Carlo (MC), finite element analysis (FEA), computational fluid dynamics (CFD), density functional theory (DFT), machine learning (ML), and dissipative particle dynamics (DPD). These techniques are critically examined in the context of drug delivery research. The article presents illustrative case studies involving liposomal, polymer-based, nano-particulate, and implantable DDSs, demonstrating the influential role of simulations in optimizing these systems. Furthermore, the review addresses the advantages and limitations of simulations in drug delivery research. It also identifies future directions for research and development, such as integrating multiple simulation techniques, refining and validating models for greater accuracy, overcoming computational limitations, and exploring applications of simulations in personalized medicine and innovative DDSs. Simulations employing various techniques like MD, MC, FEA, CFD, DFT, ML, and DPD offer crucial insights into drug behaviour, aiding in DDS design and optimization. Despite their advantages, including rapid and cost-effective screening, simulations require validation and addressing computational limitations. Future research should focus on integrating techniques, refining models, and exploring personalized medicine applications to enhance drug delivery outcomes. This paper underscores the indispensable contribution of simulations to drug research and development, emphasizing their role in providing valuable insights into drug behaviour, facilitating the development and optimization of DDSs, and ultimately enhancing patient outcomes. As we continue to explore and enhance simulation techniques, their impact on advancing drug discovery and improving DDSs is expected to be profound.}
}
@article{HU2023100795,
title = {A cardiologist-like computer-aided interpretation framework to improve arrhythmia diagnosis from imbalanced training datasets},
journal = {Patterns},
volume = {4},
number = {9},
pages = {100795},
year = {2023},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2023.100795},
url = {https://www.sciencedirect.com/science/article/pii/S2666389923001502},
author = {Lianting Hu and Shuai Huang and Huazhang Liu and Yunmei Du and Junfei Zhao and Xiaoting Peng and Dantong Li and Xuanhui Chen and Huan Yang and Lingcong Kong and Jiajie Tang and Xin Li and Heng Liang and Huiying Liang},
keywords = {arrhythmia, inter-class bullying, waveform clustering, heartbeat splicing, Bayesian approach},
abstract = {Summary
Arrhythmias can pose a significant threat to cardiac health, potentially leading to serious consequences such as stroke, heart failure, cardiac arrest, shock, and sudden death. In computer-aided electrocardiogram interpretation systems, the inclusion of certain classes of arrhythmias, which we term “aggressive” or “bullying,” can lead to the underdiagnosis of other “vulnerable” classes. To address this issue, a method for arrhythmia diagnosis is proposed in this study. This method combines morphological-characteristic-based waveform clustering with Bayesian theory, drawing inspiration from the diagnostic reasoning of experienced cardiologists. The proposed method achieved optimal performance in macro-recall and macro-precision through hyperparameter optimization, including spliced heartbeats and clusters. In addition, with increasing bullying by aggressive arrhythmias, our model obtained the highest average recall and the lowest average drop in recall on the nine vulnerable arrhythmias. Furthermore, the maximum cluster characteristics were found to be consistent with established arrhythmia diagnostic criteria, lending interpretability to the proposed method.}
}
@article{PISTIKOPOULOS2021107252,
title = {Process systems engineering – The generation next?},
journal = {Computers & Chemical Engineering},
volume = {147},
pages = {107252},
year = {2021},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2021.107252},
url = {https://www.sciencedirect.com/science/article/pii/S0098135421000302},
author = {E N Pistikopoulos and Ana Barbosa-Povoa and Jay H Lee and Ruth Misener and Alexander Mitsos and G V Reklaitis and V Venkatasubramanian and Fengqi You and Rafiqul Gani},
keywords = {Process systems engineering, Synthesis-design, Optimization, Control, Modelling, Supply chain},
abstract = {Process Systems Engineering (PSE) is the scientific discipline of integrating scales and components describing the behavior of a physicochemical system, via mathematical modelling, data analytics, design, optimization and control. PSE provides the ‘glue’ within scientific chemical engineering, and offers a scientific basis and computational tools towards addressing contemporary and future challenges such as in energy, environment, the ‘industry of tomorrow’ and sustainability. This perspective article offers a guide towards the next generation of PSE developments by looking at its history, core competencies, current status and ongoing trends.}
}
@article{NIEMYSKA2024168455,
title = {Discovery of a trefoil knot in the RydC RNA: Challenging previous notions of RNA topology},
journal = {Journal of Molecular Biology},
volume = {436},
number = {6},
pages = {168455},
year = {2024},
issn = {0022-2836},
doi = {https://doi.org/10.1016/j.jmb.2024.168455},
url = {https://www.sciencedirect.com/science/article/pii/S0022283624000214},
author = {Wanda Niemyska and Sunandan Mukherjee and Bartosz A. Gren and Szymon Niewieczerzal and Janusz M. Bujnicki and Joanna I. Sulkowska},
keywords = {Entanglement of biomolecules, Topology in soft matter, RNA 3D structure, RNA folding, Molecular dynamics},
abstract = {Knots are very common in polymers, including DNA and protein molecules. Yet, no genuine knot has been identified in natural RNA molecules to date. Upon re-examining experimentally determined RNA 3D structures, we discovered a trefoil knot 31, the most basic non-trivial knot, in the RydC RNA. This knotted RNA is a member of a small family of short bacterial RNAs, whose secondary structure is characterized by an H-type pseudoknot. Molecular dynamics simulations suggest a folding pathway of the RydC RNA that starts with a native twisted loop. Based on sequence analyses and computational RNA 3D structure predictions, we postulate that this trefoil knot is a conserved feature of all RydC-related RNAs. The first discovery of a knot in a natural RNA molecule introduces a novel perspective on RNA 3D structure formation and on fundamental research on the relationship between function and spatial structure of biopolymers.}
}
@incollection{ILLES2015735,
title = {Chapter 45 - Advances in Ethics for the Neuroscience Agenda},
editor = {Michael J. Zigmond and Lewis P. Rowland and Joseph T. Coyle},
booktitle = {Neurobiology of Brain Disorders},
publisher = {Academic Press},
address = {San Diego},
pages = {735-747},
year = {2015},
isbn = {978-0-12-398270-4},
doi = {https://doi.org/10.1016/B978-0-12-398270-4.00045-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123982704000458},
author = {Judy Illes and Peter B. Reiner},
keywords = {animal model, biomedical science, data sharing, ethics, health, incidental finding, neuroscience, public policy, science communication},
abstract = {Critical thinking about ethics in neuroscience can be a powerful force in enabling research and translating results meaningfully for society. This chapter provides four examples of such an empowered approach to neuroscience. The authors discuss how upfront consideration of the societal implications of advances in neuroscience can shape the use of animal models. They situate ethical thinking in this era of big science and big data, reflecting on strategies for sharing databases while protecting contributors and users. They highlight how collaboration among neuroscientists, ethicists, and others can produce positive measures to resolve the problem of incidental discoveries in brain imaging research, as one example of debates on incidental findings more broadly. The mandate of neuroscience research as public service and ethical imperative is addressed by describing opportunities for neuroscientists to engage with societal issues emerging from their research, and how this deepens the discourse and adds value to the research enterprise.}
}
@article{OH2015e6,
title = {The effects of simulation-based learning using standardized patients in nursing students: A meta-analysis},
journal = {Nurse Education Today},
volume = {35},
number = {5},
pages = {e6-e15},
year = {2015},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2015.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0260691715000507},
author = {Pok-Ja Oh and Kyeong Deok Jeon and Myung Suk Koh},
keywords = {Students, Nursing, Patient simulation, Meta-analysis},
abstract = {Summary
Purpose
The aim of this study was to evaluate the effect of simulation-based learning using standardized patients (SPs) on cognitive, affective, and psychomotor domain outcomes of learning in nursing students.
Methods
MEDLINE via PubMed, Cochrane Library CENTRAL, EMBASE, CINAHL, and several Korean electronic databases (to June 2014) were searched. The RevMan 5.3 program of the Cochrane library was used for data analysis.
Results
A meta-analysis was conducted of 18 controlled trials (4 randomized and 14 non-randomized designs), with a total of 1326 nursing students. Overall, simulation-based learning using SPs appeared to have beneficial effects on the cognitive, affective, and psychomotor domains of learning. In subgroup analysis, use of SPs showed significant effects on knowledge acquisition (d=0.38, p=.05, I2=42%), communication skill (d=1.86, p<.001, I2=15%), self-efficacy (d=0.61, p<.001, I2=6%), learning motivation (d=0.77, p<.001, I2=0%) and clinical competence (d=0.72, p<.001, I2=0%). Treatment effects on critical thinking (p=.75) and learning satisfaction (p=.43) were not significant.
Conclusion
The findings of the current study suggest that simulation-based learning using SPs might have a positive impact on self efficacy and learning motivation that affects knowledge and clinical skill acquisition. Therefore, these findings demonstrate that, if integrated appropriately, an SP educational approach can be used in academic settings as an active learning methodology.}
}
@article{KARIMISANI2025102651,
title = {Drug repositioning for Parkinson’s disease: An emphasis on artificial intelligence approaches},
journal = {Ageing Research Reviews},
volume = {104},
pages = {102651},
year = {2025},
issn = {1568-1637},
doi = {https://doi.org/10.1016/j.arr.2024.102651},
url = {https://www.sciencedirect.com/science/article/pii/S1568163724004690},
author = {Iman Karimi-Sani and Mehrdad Sharifi and Nahid Abolpour and Mehrzad Lotfi and Amir Atapour and Mohammad-Ali Takhshid and Amirhossein Sahebkar},
keywords = {Neurodegenerative diseases, Parkinson’s disease, Levodopa induced dyskinesia, Drug repositioning, Artificial intelligence, Machine learning, Deep learning},
abstract = {Parkinson’s disease (PD) is one of the most incapacitating neurodegenerative diseases (NDDs). PD is the second most common NDD worldwide which affects approximately 1–2 percent of people over 65 years. It is an attractive pursuit for artificial intelligence (AI) to contribute to and evolve PD treatments through drug repositioning by repurposing existing drugs, shelved drugs, or even candidates that do not meet the criteria for clinical trials. A search was conducted in three databases Web of Science, Scopus, and PubMed. We reviewed the data related to the last years (1975-present) to identify those drugs currently being proposed for repositioning in PD. Moreover, we reviewed the present status of the computational approach, including AI/Machine Learning (AI/ML)-powered pharmaceutical discovery efforts and their implementation in PD treatment. It was found that the number of drug repositioning studies for PD has increased recently. Repositioning of drugs in PD is taking off, and scientific communities are increasingly interested in communicating its results and finding effective treatment alternatives for PD. A better chance of success in PD drug discovery has been made possible due to AI/ML algorithm advancements. In addition to the experimentation stage of drug discovery, it is also important to leverage AI in the planning stage of clinical trials to make them more effective. New AI-based models or solutions that increase the success rate of drug development are greatly needed.}
}
@incollection{CAGLAR2024,
title = {Bioinformatic Applications in Neuroscience},
booktitle = {Reference Module in Life Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-12-809633-8},
doi = {https://doi.org/10.1016/B978-0-323-95502-7.00282-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955027002827},
author = {Caner Çağlar and Beyza {Kinsiz Gürsoy}},
keywords = {ALS, Alzheimer disease, Bioinformatic, DNA sequencing, Metabolomics, Neuroscience, Parkinson’s disease, Proteomics, Psychiatric disorders, Radiomics, Transcriptomics},
abstract = {In the last decade of the 20th century, interest in neuroscience significantly increased, prioritizing the study of neurological diseases and treatments. This chapter examines how the integration of neuroscience and bioinformatics has enhanced our grasp of neurological and psychiatric disorders. Combining computational methods with neuroscience allows for the analysis of large datasets, uncovering the genetic, molecular, and neural foundations of diseases. Advances in genomics, transcriptomics, and proteomics, along with the integration of radiomics and metabolomics, have transformed our understanding of brain function and disease mechanisms. By enabling non-invasive, quantitative analysis of medical images, radiomics further enhances diagnostic precision and prognostic insights. Future research will focus on using AI and machine learning for personalized medicine and targeted therapeutic development.}
}
@article{KEE1984198,
title = {Computational modeling of flame structure},
journal = {Physica D: Nonlinear Phenomena},
volume = {12},
number = {1},
pages = {198-211},
year = {1984},
issn = {0167-2789},
doi = {https://doi.org/10.1016/0167-2789(84)90524-4},
url = {https://www.sciencedirect.com/science/article/pii/0167278984905244},
author = {Robert J. Kee and James A. Miller},
abstract = {In this paper we discuss the need to model the detailed structure of a flame. That is, we argue the value of tracing the elementary reaction steps that are responsible for the creation of pollutant species and the release of heat. Accomplishing this task requires the computational solution of equations describing the conservation of mass, momentum, energy, and chemical species. In the course of our development we compare the computational approach with that of large activation energy asymptotic analysis. In the second half of the paper we concentrate on the computational consequences of flame modeling. Typically the governing equations are large and stiff systems of partial differential equations. Computational solution requires strongly stable implicit numerical algorithms, and we discuss these methods. We also discuss the adaptive meshing strategies that are required to resolve accurately the structure of thin flames in relatively large domains.}
}
@article{DO2000483,
title = {Intentions in and relations among design drawings},
journal = {Design Studies},
volume = {21},
number = {5},
pages = {483-503},
year = {2000},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(00)00020-X},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X0000020X},
author = {Ellen Yi-Luen Do and Mark D Gross and Bennett Neiman and Craig Zimring},
keywords = {drawing(s), architectural design, case study/studies, design activity, design research},
abstract = {Designers use drawings to explore alternatives and to test ideas. We report here on two studies on design and drawing. The first study of design drawing symbols aims to determine whether and to what extent it is possible to infer, interpret, or even guess what a designer was thinking about by looking at the drawings she has made. In the second study we examined a collection of drawings for the design of a house to investigate the systems of design transformations. Drawings are characterized by drawing style, projection type, and key elements. We analyzed the relationships among the drawings and developed a notation system for documenting these relationships.}
}
@article{ENE20141110,
title = {Open Loop Reverse Supply Chain Network Design},
journal = {Procedia - Social and Behavioral Sciences},
volume = {109},
pages = {1110-1115},
year = {2014},
note = {2nd World Conference on Business, Economics and Management},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.12.596},
url = {https://www.sciencedirect.com/science/article/pii/S187704281305235X},
author = {Seval Ene and Nursel Öztürk},
keywords = {Supply chain management, open loop system, product recovery, network design, mathematical programming},
abstract = {Reverse supply chain management is a significant issue for sustainable economy, product recovery and green thinking. The purpose of this study is to contribute product recovery management by designing open loop reverse supply chain network. The main difference between open loop and closed loop reverse supply chain is in returning of used products. In a closed loop reverse supply chain, used products are generally returned to original producers. But in an open loop reverse supply chain, used products are not returned to original producers, outsider firms recover them. This paper presents a mathematical model for multi stage and multi period reverse supply chain network, which maximizes total profit of the network. The proposed model determines facility locations and material flows between stages in each period. Numerical experiments showed the applicability and efficiency of the model.}
}
@article{KULAKOVA2024103762,
title = {Comparing third-party responsibility with intention attribution: An fMRI investigation of moral judgment},
journal = {Consciousness and Cognition},
volume = {125},
pages = {103762},
year = {2024},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2024.103762},
url = {https://www.sciencedirect.com/science/article/pii/S1053810024001296},
author = {Eugenia Kulakova and Sofia Bonicalzi and Adrian L. Williams and Patrick Haggard},
keywords = {Moral responsibility, Intention, Social cognition, Causality},
abstract = {Neuroimaging studies demonstrate that moral responsibility judgments activate the social cognition network, presumably reflecting mentalising processes. Conceptually, establishing an agent’s intention is a sub-process of responsibility judgment. However, the relationship between both processes on a neural level is poorly understood. To date, neural correlates of responsibility and intention judgments have not been compared directly. The present fMRI study compares neural activation elicited by third-party judgments of responsibility and intention in response to animated pictorial stimuli showing harm events. Our results show that the social cognition network, in particular Angular Gyrus (AG) and right Temporo-Parietal Junction (RTPJ), showed stronger activation during responsibility vs. intention evaluation. No greater activations for the reverse contrast were observed. Our imaging results are consistent with conceptualisations of intention attribution as a sub-process of responsibility judgment. However, they question whether the activation of the social cognition network, particularly AG/RTPJ, during responsibility judgment is limited to intention evaluation.}
}
@article{BAILLIE1989209,
title = {A comparison of the CM with the DAP for lattice gauge theory},
journal = {Parallel Computing},
volume = {12},
number = {2},
pages = {209-220},
year = {1989},
issn = {0167-8191},
doi = {https://doi.org/10.1016/0167-8191(89)90054-9},
url = {https://www.sciencedirect.com/science/article/pii/0167819189900549},
author = {Clive F Baillie and G {Stuart Pawley}},
keywords = {Connection Machine, Distributed Array Processor, SIMD, massively parallel, lattice gauge theory, QED, QCD, performance measurement, performance analysis},
abstract = {Lattice gauge theory is one of the most challenging large-scale scientific computations; a state of the art calculation requires at least 1014 floating-point operations, necessitating the use of advanced architecture massively parallel computers such as the Connection Machine (CM) made by Thinking Machines Corporation (TMC), and the Distributed Array Processor (DAP) made in the past by International Computers Limited (ICL) and currently by active Memory Technology (AMT). The most important gauge theory to be solved is that descrining the sub-nuclear world of high energy physics: Quantum Chromodynamics (QCD). The simples example of a gauge theory is Quantum Electro-dynamics (QED), the theory which describes the interaction of electrons and photons. Simulation of QCD requires computer software very similar to that for the simpler QED problem. Thus, as a first step towards computer simulation of QCD, we have developed code for QED on the CM, and compared this with similar code for the DAP. Experience with the DAP allows us to predict performances for QCD code on the CM, showing the latter to be a very serious proposition for such large-scale scientific computations.}
}
@article{OSTLUND1985109,
title = {WATERLOPP V2/64: A highly parallel machine for numerical computation},
journal = {Computer Physics Communications},
volume = {37},
number = {1},
pages = {109-117},
year = {1985},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(85)90142-0},
url = {https://www.sciencedirect.com/science/article/pii/0010465585901420},
author = {Neil S. Ostlund},
abstract = {Current technological trends suggest that the high performance scientific machines of the future are very likely to consist of a large number (greater than 1024) of processors connected and communicating with each other in some as yet undetermined manner. Such an assembly of processors should behave as a single machine in obtaining numerical solutions to scientific problems. However, the appropriate way of organizing both the hardware and software of such an assembly of processors is an unsolved and active area of research. It is particularly important to minimize the organizational overhead of interprocessor comunication, global synchronization, and contention for shared resources if the performance of a large number (n) of processors is to be anything like the desirable n times the performance of a single processor. In many situations, adding a processor actually decreases the performance of the overall system since the extra organizational overhead is larger than the extra processing power added. The systolic loop architecture is a new multiple processor architecture which attemps at a solution to the problem of how to organize a large number of asynchronous processors into an effective computational system while minimizing the organizational overhead. This paper gives a brief overview of the basic systolic loop architecture, systolic loop algorithms for numerical computation, and a 64-processor implementation of the architecture, WATERLOOP V2/64, that is being used as a testbed for exploring the hardware, software, and algorithmic aspects of the architecture.}
}
@article{DUGGAN2024100102,
title = {The digital geographies of tact},
journal = {Digital Geography and Society},
volume = {7},
pages = {100102},
year = {2024},
issn = {2666-3783},
doi = {https://doi.org/10.1016/j.diggeo.2024.100102},
url = {https://www.sciencedirect.com/science/article/pii/S2666378324000242},
author = {Mike Duggan},
keywords = {Tact, Tactics, Tactility, Touch, Social behaviour, Judgement, Space, Digital media, Artificial intelligence},
abstract = {This article outlines a research agenda for the spatialities of tact produced by, through and of digital spaces. As a discipline interested in what and who characterises digital space, and in how different relations come to produce space, the article puts forward a proposition for geographers to take tact seriously as an inherently spatial concept useful for theorising the production of space in our digital society. The paper identifies three strands of tact from the literature, 1) tact and social behaviour, 2) tact and touch, 3) tact and judgement, and outlines what they can offer geography in terms of a novel framework for studying digital society. It raises questions of how and why digital spaces and practices produce new trajectories for displays of tact in everyday life, how digital spaces modulate our understanding and experiences of touch, as well as asking whether algorithmic decision making technologies such as Artificial Intelligence have a capacity for tact, and what that means for the geographies these systems shape. The work makes a contribution to the discipline's long standing interests in spatial tactics and socio-spatial behaviour, in touch and sensory geographies, and more recently to algorithmic decision making.}
}
@article{WILKINSON2024168584,
title = {Environmental impacts of earth observation data in the constellation and cloud computing era},
journal = {Science of The Total Environment},
volume = {909},
pages = {168584},
year = {2024},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2023.168584},
url = {https://www.sciencedirect.com/science/article/pii/S0048969723072121},
author = {R. Wilkinson and M.M. Mleczko and R.J.W. Brewin and K.J. Gaston and M. Mueller and J.D. Shutler and X. Yan and K. Anderson},
keywords = {Cloud computing, Satellite, Data centre, Carbon intensity, Environmental impacts},
abstract = {Numbers of Earth Observation (EO) satellites have increased exponentially over the past decade reaching the current population of 1193 (January 2023). Consequently, EO data volumes have mushroomed and data storage and processing have migrated to the cloud. Whilst attention has been given to the launch and in-orbit environmental impacts of satellites, EO data environmental footprints have been overlooked. These issues require urgent attention given data centre water and energy consumption, high carbon emissions for computer component manufacture, and difficulty of recycling computer components. Doing so is essential if the environmental good of EO is to withstand scrutiny. We provide the first assessment of the EO data life-cycle and estimate that the current size of the global EO data collection is ~807 PB, increasing by ~100 PB/year. Storage of this data volume generates annual CO2 equivalent emissions of 4101 t. Major state-funded EO providers use 57 of their own data centres globally, and a further 178 private cloud services, with considerable duplication of datasets across repositories. We explore scenarios for the environmental cost of performing EO functions on the cloud compared to desktop machines. A simple band arithmetic function applied to a Landsat 9 scene using Google Earth Engine (GEE) generated CO2 equivalent (e) emissions of 0.042–0.69 g CO2e (locally) and 0.13–0.45 g CO2e (European data centre; values multiply by nine for Australian data centre). Computation-based emissions scale rapidly for more intense processes and when testing code. When using cloud services such as GEE, users have no choice about the data centre used and we push for EO providers to be more transparent about the location-specific impacts of EO work, and to provide tools for measuring the environmental cost of cloud computation. The EO community as a whole needs to critically consider the broad suite of EO data life-cycle impacts.}
}
@article{RUTHVEN2004259,
title = {Teacher representations of the successful use of computer-based tools and resources in secondary-school English, mathematics and science},
journal = {Teaching and Teacher Education},
volume = {20},
number = {3},
pages = {259-275},
year = {2004},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2004.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X04000113},
author = {Kenneth Ruthven and Sara Hennessy and Sue Brindley},
keywords = {Computer uses in education, Educational technology, Teacher attitude and cognition, Subject teaching and learning, Secondary education, England},
abstract = {This study investigated professional thinking about pedagogical aspects of technology use in mainstream classroom practice. It focuses on the systems of ideas which frame teacher accounts of the successful use of computer-based tools and resources in the core subjects of English, Mathematics and Science at secondary-school level. These accounts were elicited through group interviews with the relevant subject departments in six secondary schools in England. The analysis identifies seven broad themes in which teachers point to the contribution of technology use in: effecting working processes and improving production; supporting processes of checking, trialling and refinement; enhancing the variety and appeal of classroom activity; fostering pupil independence and peer support; overcoming pupil difficulties and building assurance; broadening reference and increasing currency of activity; and focusing on overarching issues and accentuating important features. Further examination of these themes shows how professional thinking about technology use is anchored in well-established representations of pupil motivation and classroom learning, and how contrasting subject profiles reflect corresponding differences in wider subject cultures.}
}
@article{CRISTOFARO2020344,
title = {“I feel and think, therefore I am”: An Affect-Cognitive Theory of management decisions},
journal = {European Management Journal},
volume = {38},
number = {2},
pages = {344-355},
year = {2020},
issn = {0263-2373},
doi = {https://doi.org/10.1016/j.emj.2019.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0263237319301094},
author = {Matteo Cristofaro},
keywords = {Sensemaking, Decision making, Socially situated cognition, Affect, Cognition, Rationality, Behavioral strategy},
abstract = {I propose an Affect-Cognitive Theory to comprehensively understand how decisions occur in organizations. To this aim, I first review the assumptions of sensemaking and decision-making streams of research, especially the influence of bounded rationality, affective states and their relationships with cognition; then, I integrate them on the common basis of socially situated cognition. This new theory emphasizes the role of affective states in determining/being determined by cognition and its errors, pointing out decision makers’ affect as the result of multi-level adaptations to the physical and social environment. Management decisions are path dependent but not immutable; they, indeed, bank on the predominant feeling resulting from the modifying interactions and regulations of decision makers with their physical and social environment. Here, decision makers are proposed as “emotional cognizers” overcoming the thinking-feeling dichotomy that has often featured in the study of management decisions. This theory is beneficial for behavioral strategy, offering the needed assumptions to intertwine human cognition, emotions, and social behavior.}
}
@incollection{EVETT1994115,
title = {Chapter 6 - Providing Computationally Effective Knowledge Representation via Massive Parallelism},
editor = {Laveen N. KANAL and Vipin KUMAR and Hiroaki KITANO and Christian B. SUTTNER},
series = {Machine Intelligence and Pattern Recognition},
publisher = {North-Holland},
volume = {14},
pages = {115-135},
year = {1994},
booktitle = {Parallel Processing for Artificial Intelligence},
issn = {0923-0459},
doi = {https://doi.org/10.1016/B978-0-444-81704-4.50012-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780444817044500120},
author = {Matthew P. Evett and William A. Andersen and James A. Hendler},
abstract = {PARKA is a frame-based knowledge representation system implemented on the Connection Machine. PARKA provides a representation language consisting of concept descriptions (frames) and binary relations on those descriptions (slots). The system is designed explicitly to provide extremely fast property inheritance inference capabilities. In particular, PARKA can perform fast “recognition” queries of the form “find all frames satisfying m property constraints” in O(d + m) time—proportional only to the depth (d) of the knowledge base (KB), and independent of its size. For conjunctive queries of this type, PARKA's performance is measured in tenths of a second, even for KBs with more than 100,000 frames. We show similar results for timings on on large IS-A networks derived from the Cyc commonsense KB, and for queries involving knowledge structure pattern matching in support of case-based planning. With such run-time performance, PARKA is possibly the “fastest knowledge representation system in the world”.}
}
@article{CHRISTAKOU2014302,
title = {Present simple and continuous: Emergence of self-regulation and contextual sophistication in adolescent decision-making},
journal = {Neuropsychologia},
volume = {65},
pages = {302-312},
year = {2014},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2014.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0028393214003133},
author = {Anastasia Christakou},
keywords = {Decision-making, Adolescence, Self-regulation, Corticostriatal circuits},
abstract = {Sophisticated, intentional decision-making is a hallmark of mature, self-aware behaviour. Although neural, psychological, interpersonal, and socioeconomic elements that contribute to such adaptive, foresighted behaviour mature and/or change throughout the life-span, here we concentrate on relevant maturational processes that take place during adolescence, a period of disproportionate developmental opportunity and risk. A brief, eclectic overview is presented of recent evidence, new challenges, and current thinking on the fundamental mechanisms that mature throughout adolescence to support adaptive, self-controlled decision-making. This is followed by a proposal for the putative contribution of frontostriatal mechanisms to the moment-to-moment assembly of evaluative heuristics that mediate increased decision-making sophistication, promoting the maturation of self-regulated behaviour through adolescence and young adulthood.}
}
@article{GHIMIRE2025102913,
title = {Utilizing ChatGPT to integrate world English and diverse knowledge: A transnational perspective in critical artificial intelligence (AI) literacy},
journal = {Computers and Composition},
volume = {75},
pages = {102913},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102913},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000896},
author = {Asmita Ghimire},
abstract = {This article proposes the implementation of a transnational post-digital pedagogy and Critical AI literacy incorporating ChatGPT in the classroom. It draws upon Scott Graham's suggestion for a multidimensional recursive writing process, emphasizing fact-checking and revision while utilizing ChatGPT. Additionally, it incorporates Suresh Canagarajah's (2019) theorization of transnational habits of writing among most international, multilingual, and marginalized students, which, according to him, are characterized by rhetorical sensitivity, depth of awareness, and linguistic knowledge. Based on these empirical and theoretical perspectives, this article proposes pausing, pondering, posing, and prioritizing as critical praxis that can be built into metacognitive activities. To explain this praxis, it showcases two kinds of metacognitive activities for fostering transnational habits among students through fact-checking processes. Similarly, it suggests designing the revision phase of writing assignments to allow students to incorporate their English language skills into the classroom. This paper identifies engaging in critical dialogue with ChatGPT and encouraging self-reflection on fact-checking and revision as effective ways to cultivate a transnational habitus among students. It concludes that adopting a transnational post-digital critical pedagogy and critical AI literacy in the writing process benefits both national and international students by promoting diverse linguistic norms and perspectives.}
}
@article{KRELLENSTEIN1987155,
title = {A reply to ”parallel computation and the mind-body problem”},
journal = {Cognitive Science},
volume = {11},
number = {2},
pages = {155-157},
year = {1987},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(87)80003-4},
url = {https://www.sciencedirect.com/science/article/pii/S0364021387800034},
author = {Marc Krellenstein}
}
@article{TSAI2017997,
title = {An empirical study on the incorporation of APP and progressive reasoning teaching materials for improving technical creativity amongst students in the subject of automatic control},
journal = {Computers in Human Behavior},
volume = {75},
pages = {997-1007},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.10.031},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216307117},
author = {Hsieh–Chih Tsai and Min Jou and JingYing Wang and Chun-Chiang Huang},
keywords = {APP, Progressive reasoning, Technical creativity, Scientific reasoning},
abstract = {This study reformed teaching materials for automatic control, a mandatory course for engineering students, and designed a set of digital teaching materials based upon progressive reasoning with hand-mind combinations. The teaching materials were mainly delivered via a hands-on APP. The authors conducted an empirical study as well as pre-tests and post-tests for a total of 118 sophomore students majoring in engineering at two Universities. Outcomes found that the progressive reasoning teaching materials designed for this course were helpful in improving student creativity and scientific reasoning. Significant improvements were also achieved in product design, technical methods, and technological ideas aspects of technological creativity and every scientific reasoning skill, with the exception of proportional reasoning. Results also identified strong correlation between technical creativity and scientific reasoning. This relationship may be further investigated in follow-up studies. This study also proposed recommendations for coordinating designs of digital teaching materials in other engineering courses with the development of student thinking.}
}
@article{MILLER2025105387,
title = {Biological mechanisms contradict AI consciousness: The spaces between the notes},
journal = {BioSystems},
volume = {247},
pages = {105387},
year = {2025},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105387},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724002727},
author = {William B. Miller and František Baluška and Arthur S. Reber and Predrag Slijepčević},
keywords = {Consciousness, Cellular basis of consciousness, Cognition-based evolution, Information field, Artificial intelligence, Senome},
abstract = {The presumption that experiential consciousness requires a nervous system and brain has been central to the debate on the possibility of developing a conscious form of artificial intelligence (AI). The likelihood of future AI consciousness or devising tools to assess its presence has focused on how AI might mimic brain-centered activities. Currently, dual general assumptions prevail: AI consciousness is primarily an issue of functional information density and integration, and no substantive technical barriers exist to prevent its achievement. When the cognitive process that underpins consciousness is stipulated as a cellular attribute, these premises are directly contradicted. The innate characteristics of biological information and how that information is managed by individual cells have no parallels within machine-based AI systems. Any assertion of computer-based AI consciousness represents a fundamental misapprehension of these crucial differences.}
}
@article{ACAR2016861,
title = {Soundscapes of Digital Morphogenesis in Architecture which Created from Musical Algorithm},
journal = {Procedia - Social and Behavioral Sciences},
volume = {216},
pages = {861-873},
year = {2016},
note = {Urban Planning and Architectural Design for Sustainable Development (UPADSD)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.12.083},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815062631},
author = {Didem Acar},
keywords = {Transcoding, Acoustic, Computational Design, Transdisciplinary framework, Architectural design},
abstract = {Music and architecture have made use of mathematical proportions throughout the history for the purpose of creating acoustic and visual forms. The reason for this is the aesthetic pursuit of both disciplines since centuries. Mathematics is one of the most important factors that influence aesthetic results. While forming their abstract aesthetic compositions the musicians use the musical notes that have definite frequency values. Each of these frequency values are defined by one integer. Every classical music artist uses the fractal sequencing of these frequencies. On the other hand we encounter hundreds of silent formats which are produced using mathematical ideas. In this context if we think of the interdisciplinary interaction between music and architecture no form is ever silent. In this study, the intersection of two disciplines will be examined in the perspective of architecture; a stumper and interrogative start for pursuit of architectural forms of the present day with the transformation of auditory forms to visual forms will be made; and a basis will be provided to be able to discuss the innovations that the spaces, structures and auditory experiences which can be formed by obtaining musical codes bring.}
}
@incollection{CHIARENZA202317,
title = {Chapter 2 - The psychophysiology of “covert” goal-directed behavior},
editor = {Tal Dotan Ben-Soussan and Joseph Glicksohn and Narayanan Srinivasan},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {280},
pages = {17-42},
year = {2023},
booktitle = {Neurophysiology of Silence Part B: Theory and Review},
issn = {0079-6123},
doi = {https://doi.org/10.1016/bs.pbr.2023.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0079612323000067},
author = {Giuseppe Augusto Chiarenza},
keywords = {Covert behavior, Movement related potentials, Bereitschaftspotential, Skilled performance positivity, Development, Dyslexia, Education},
abstract = {Covert behavior is defined as behavior that is not directly visible and is thus comparable to a type of behavioral silence that requires modern psychophysiological techniques to reveal. Goal-directed behavior is teleologically purposive. Fundamentally, there are two approaches to accounting for purposeful behavior. One is the cybernetic approach, which views behavior as homeostatic and largely reflexive. The other one views behavior as a cognitive process that involves an interaction between neural events representing the previous experience, the present state of the individual, and the occurrence of particular features in the environment. This review, based on published data, presents a non-invasive psychophysiological method for investigating the electrical brain activity associated with those “silent” behaviors such as intention, evaluation of results, and memorization. Movement-related potentials (MRPs) are ideal for studying these processes. The MRPs are recorded during the execution of the skilled performance task (SPT). This task requires the execution of fast ballistic movements with the thumbs of both hands, learning a precise and short time interval between the two thumb presses, and scoring the highest number of target performances. The subject receives real-time feedback about the results of his performance. The MRPs associated with this task and present during covert behavior are the Bereitschaftspotential (BP) present before the onset of movement and the Skilled Performance Positivity (SPP) after movement, which coincides with the subject's awareness of the success or failure of his performance. These potentials show a maturational trend, reaching the adult form around the age of 10 when formal and abstract thinking progress. SPT and MRPs are particularly suitable to study neurodevelopmental disorders. Children with developmental dyslexia show abnormal MRPs, both in latency and amplitude, in different brain areas.}
}
@article{AYERS201861,
title = {A first step toward a practice-based theory of pedagogical content knowledge in secondary economics},
journal = {The Journal of Social Studies Research},
volume = {42},
number = {1},
pages = {61-79},
year = {2018},
issn = {0885-985X},
doi = {https://doi.org/10.1016/j.jssr.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0885985X17300177},
author = {Cheryl A. Ayers},
keywords = {Secondary economic education, Pedagogical content knowledge, Horizon content knowledge, Specialized content knowledge, Knowledge of content and teaching, Knowledge of content and students},
abstract = {The purpose of this qualitative case study was to gain an in-depth understanding of how three award-winning secondary economics teachers demonstrated their pedagogical content knowledge (PCK), specifically horizon content knowledge, specialized content knowledge, knowledge of content and teaching, and knowledge of content and students. The teachers consistently connected economic content to other grades, subjects, and economic concepts and skills. Economic content was also regularly used to prepare students for citizenship, including casting more informed votes and understanding current events. However, authentic discussions, including ones about controversial issues, were mostly lacking. An emphasis was placed on developing students’ economic reasoning skills, including real-world applications of the economic way of thinking and decision-making models. Additionally, active learning instructional practices were frequently incorporated, and economic content was almost always related to students’ interests and experiences. A detailed description of a first step toward a practice-based theory of PCK in secondary economics concludes the article.}
}
@article{GREENLEE20201043,
title = {Kinetic and Thermodynamic Control in Dynamic Covalent Synthesis},
journal = {Trends in Chemistry},
volume = {2},
number = {12},
pages = {1043-1051},
year = {2020},
issn = {2589-5974},
doi = {https://doi.org/10.1016/j.trechm.2020.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S258959742030232X},
author = {Andrew J. Greenlee and Chloe I. Wendell and Morgan M. Cencer and Summer D. Laffoon and Jeffrey S. Moore},
keywords = {dynamic, covalent, reversible, kinetic, thermodynamic},
abstract = {In recent years, dynamic covalent chemistry (DCC) has seen the synthesis of increasingly complex cyclooligomers, polymers, and diverse compound libraries. The reversible formation of covalent bonds characteristic of DCC reactions favors thermodynamic product distributions for simple unitopic reactions; however, kinetic effects are increasingly influential in reactions of multitopic precursors. In this review, we explore the interplay between thermodynamic and kinetic considerations when planning a DCC synthesis. Computational models, typically based on reaction thermodynamics, have aided in predicting DCC reaction outcomes with moderate success. A clear direction for the field is to develop more robust computational tools informed by thermodynamic and kinetic driving forces that can predict product distributions in DCC reactions.}
}
@article{FUNG20243519,
title = {Chemical education in digital chemistry},
journal = {Chem},
volume = {10},
number = {12},
pages = {3519-3525},
year = {2024},
issn = {2451-9294},
doi = {https://doi.org/10.1016/j.chempr.2024.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S2451929424005369},
author = {Fun Man Fung and Magdalena Lederbauer and Yvonne S.L. Choo and Timo Gehring and Kevin Maik Jablonka and Kjell Jorner and Philippe Schwaller and Michael B. Sullivan and Andrea Volkamer and Matthew S. Sigman and Kuangbiao Liao and Charles Windle},
abstract = {In this digital age where machine learning has won the Nobel Prizes in both Physics and Chemistry, it is ever more important to give chemistry students an educational advantage that will enable them to use the tools of artificial intelligence and machine learning to enhance both their study experience and their future research. In this Voices article, chemistry education and research experts gather to share their implementation and utilization of these data-driven tools in classes and in labs.}
}
@article{1989N1,
title = {Newsletter on computational and applied mathematics},
journal = {Journal of Computational and Applied Mathematics},
volume = {25},
number = {2},
pages = {N1-N18},
year = {1989},
issn = {0377-0427},
doi = {https://doi.org/10.1016/0377-0427(89)90050-2},
url = {https://www.sciencedirect.com/science/article/pii/0377042789900502}
}
@article{COIERA2007S98,
title = {Putting the technical back into socio-technical systems research},
journal = {International Journal of Medical Informatics},
volume = {76},
pages = {S98-S103},
year = {2007},
note = {Information Technology in Health Care: Sociotechnical Approaches},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2006.05.026},
url = {https://www.sciencedirect.com/science/article/pii/S1386505606001481},
author = {Enrico Coiera},
keywords = {Human–computer interaction, Information system design, Information system evaluation, Socio-technical systems},
abstract = {Socio-technical systems (STS) analysis has provided us with a powerful framework with which to analyse the reasons behind the poor acceptability, uptake and performance of many information or communication technology systems (ICT). However, for the contribution of STS thinking to be more than simply a means of critiquing current practices and ICT systems, it needs to also contribute to the process of developing new and more effective ICT systems. Specifically, we need to develop a formal design language for translating our insights about the socio-technical nature of work, into design specifications that result in better interventions in the work place. We need to get ‘technical’ about what we mean and about what we want from a design, and we need to work alongside technologists to shape technology, as well as the processes, organisations and cultures within which they will be embedded. Indeed the process of design itself can be seen as a socio-technical one, and understanding the decision to design itself may allow us one day to stop designing for people, and create STS that sustainably design themselves.}
}
@article{YE2024116982,
title = {A fast cosine transformation accelerated method for predicting effective thermal conductivity},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {426},
pages = {116982},
year = {2024},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2024.116982},
url = {https://www.sciencedirect.com/science/article/pii/S004578252400238X},
author = {Changqing Ye and Shubin Fu and Eric T. Chung},
keywords = {Effective thermal conductivity, Preconditioner, Fast cosine transformation, CUDA, GPU},
abstract = {Predicting effective thermal conductivity by solving a Partial Differential Equation (PDE) defined on a high-resolution Representative Volume Element (RVE) is a computationally intensive task. In this paper, we tackle the task by proposing an efficient and implementation-friendly computational method that can fully leverage the computing power offered by hardware accelerators, namely, graphical processing units (GPUs). We first employ the Two-Point Flux-Approximation scheme to discretize the PDE and then utilize the preconditioned conjugate gradient method to solve the resulting algebraic linear system. The construction of the preconditioner originates from FFT-based homogenization methods, and an engineered linear programming technique is utilized to determine the homogeneous reference parameters. The fundamental observation presented in this paper is that the preconditioner system can be effectively solved using multiple Fast Cosine Transformations (FCT) and parallel tridiagonal matrix solvers. Regarding the fact that default multiple FCTs are unavailable on the CUDA platform, we detail how to derive FCTs from FFTs with nearly optimal memory usage. Numerical experiments including the stability comparison with standard preconditioners are conducted for 3D RVEs. Our performance reports indicate that the proposed method can achieve a 5-fold acceleration on the GPU platform over the pure CPU platform and solve the problems with 5123 degrees of freedom and reasonable contrast ratios in less than 30 s.}
}
@article{HOZ2024e40032,
title = {Educational robotics for science and mathematics teaching: Analysis of pre-service teachers' perceptions and self-confidence},
journal = {Heliyon},
volume = {10},
number = {21},
pages = {e40032},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e40032},
url = {https://www.sciencedirect.com/science/article/pii/S240584402416063X},
author = {Alejandro De la Hoz and Lina Melo and Florentina Cañada and Javier Cubero},
keywords = {Educational robotics, Pre-service teachers, Self-confidence, Perception, Mathematics education, Science education},
abstract = {Educational Robotics has had an important impact in recent years as it offers a number of advantages for students. The inclusion of robotics in any educational stage requires teachers with adequate predisposition and training, making it necessary to know the opinions of pre-service teachers. The aim of our study is to analyze the perceptions and self-confidence of 109 pre-service primary education teachers before and after an intervention based on educational robotics and challenge-based learning to teach scientific and mathematical content, in their third academic year. A quasi-experimental design was used involving pretest and posttest, using the nonparametric Mann-Whitney and Wilcoxon U tests. The results showed a significant improvement in the overall mean self-confidence. In addition, the intervention led to a more positive perception of the benefits and possibilities of robotics for teaching of scientific and mathematical content, although it also increased the difficulties of implementation due to the lack of training in this digital resource. It is concluded that interventions are required based on educational robotics that allow pre-service teachers to gain the necessary self-confidence and perception to facilitate its introduction for the teaching of scientific and mathematical content.}
}
@article{OBIEKE2020373,
title = {Supporting Design Problem-exploring with Emergent Technologies},
journal = {Procedia CIRP},
volume = {91},
pages = {373-381},
year = {2020},
note = {Enhancing design through the 4th Industrial Revolution Thinking},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2020.02.189},
url = {https://www.sciencedirect.com/science/article/pii/S2212827120308362},
author = {Chijioke Obieke and Jelena Milisavljevic-Syed and Ji Han},
keywords = {Creativity, Design Process, Industry 4.0, Problem-exploring},
abstract = {The goal in this study is to highlight the value of using emergent technologies to support human effort in identifying creative design problems. First, we explore the relationship between design and creativity - a popular concept and an important requirement in engineering design process. A search is conducted across repositories. This includes search in Google, Google Scholar and Google Books databases in addition to others. Findings show that the extent to which the design process requires creativity is somewhat obscure and not generally perceptible. We observe that creativity consists of two aspects: problem-solving and problem-exploring. We also observe that creativity drives the design process, not by the way of problem-solving but by the way of problem-exploring. However, currently, focus is on problem-solving than the equally important problem-exploring. For every 135 studies on problem-solving, there is only one on problem-exploring. Study on problem-exploring is limited. We research further and identify some determinants of the neglect in problem-exploring in design. These determinants are lack of motivation, significant level of difficulty and the presence of many problems yet unsolved. Using the X-Design Process model and Problem-dependent Solution model we show the importance and benefits of problem-exploring in design and why it deserves attention. Consequently, we illustrate the use of emergent technologies to support problem-exploring in design and give reasons why this is possible in Industry 4.0. These technologies include data mining, natural language processing, machine learning, duplication recognition, and so on. We indicate that these technologies will only play subordinate role to humans towards inspiring problem-exploring in design. Also, we state that a precondition to applying these technologies is a study of the human problem-exploring cognition process for subsequent simulation. Success in computational problem-exploring would lead to breakthroughs in global problem-exploring and trigger more creative solutions in coming years.}
}
@article{WANG201837,
title = {Linguistic terms with weakened hedges: A model for qualitative decision making under uncertainty},
journal = {Information Sciences},
volume = {433-434},
pages = {37-54},
year = {2018},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.12.036},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517311593},
author = {Hai Wang and Zeshui Xu and Xiao-Jun Zeng},
keywords = {Decision making, Linguistic hedges, Linguistic term sets, Multi-granularity linguistic decision making, Semantics},
abstract = {When expressing the experts’ opinions in qualitative decision making (QDM), linguistic hedges can be considered to modify the force expressed by a predefined linguistic term. If an expert is not sure to select one term, weakened hedges would be a natural way to express the uncertainty. This is usually implemented by using a hedge to modify the most possible term, like the expression “more or less good”. To model the uncertainty implied by hedges in QDM, this paper presents a novel linguistic representational and computational model in which the linguistic expressions take the form of a weakened hedge and a linguistic term, which is named as linguistic term with weakened hedge (LTWH). The syntax of LTWHs is defined by a set of hedges and a set of linguistic terms. The semantics of a LTWH is determined, objectively, based on the semantics of the term and a similarity measure of the reference domain. Accordingly, the negation, order relations and some basic operations of LTWHs are defined. To illustrate the effectiveness of LTWHs in granular computing, the connection to some multi-granularity linguistic models is exploited and a process for unifying multi-granularity linguistic information is developed. The major contritions of this paper are: (1) The proposed model enables a new manner to express and operate uncertain linguistic information in QDM; (2) it possesses clear syntax and semantics and the computational results are very interpretable; and (3) the proposed solution of multi-granularity linguistic unification maintains the semantics of the original linguistic information.}
}
@article{VAR2025e41447,
title = {A new strategy for constructing alternative consumer confidence indexes to explain household consumption: A fuzzy DEMATEL approach},
journal = {Heliyon},
volume = {11},
number = {2},
pages = {e41447},
year = {2025},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e41447},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024174786},
author = {Özge Var and Alptekin Durmuşoğlu and Türkay Dereli},
keywords = {Consumer confidence index, Consumer surveys, Fuzzy DEMATEL, Household consumption, Lasso regression},
abstract = {Background
Consumer Confidence Index (CCI) is a measure obtained from consumer surveys (CS) that gauges assessments and expectations of the economic environment. Common practice uses 4 of the 12 questions in CCI calculation. However, efforts to find best set of questions continue, such as the European Commission swapping two questions in 2019. Literature studies employ different combinations of questions; however all-alternative combinations take too much time and computational power. The questions also exhibit cause-and-effect relationships as household consumption predictors and are not statistically independent of one another.
Objective
We suggest classifying the CS questions as "Causes" and "Effects." It makes sense that inquiries in the cause group should provide a better explanation of household consumption. If this theory turns out to be correct, a smaller solution space will be able to be used to find the ideal substitute CCI.
Method
A fuzzy DEMATEL (Decision-Making Trial and Evaluation Laboratory), a reliable method to present causal relationships, is used to classification. The prediction power of cause group (in terms of explaining household expenditures) is measured with the Lasso regression (Least Absolute Shrinkage and Selection Operator), which provides more interpretable regression models. This approach was applied to European Union dataset from 2007Q3 to 2021Q2.
Results
The cause group included four CS questions and explained the 75% variability of the consumption expenditures. It is performed comparably to earlier studies that took into account all possible question combinations. The Türkiye case, covering data from 2007 to 2021, supported the finding of EU case, explaining 84% variation in consumption expenditures.
Conclusion
These encouraging results suggest that comparable prediction power can be attained with a significant reduction in effort (in comparison to all brute force). Therefore, this approach would provide shortcut for constructing alternative CCIs to the authorities.}
}
@incollection{EDELMAN2015596,
title = {Marr, David (1945–80)},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {596-598},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.61085-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868610851},
author = {Shimon Edelman and Lucia M Vaina},
keywords = {Biological information processing, Brain function, Cognitive psychology, Computational theory and modeling, Neuroscience, Scientific methodology, Vision},
abstract = {David Courtnay Marr was born in 1945 in Essex, England. Marr's dissertation, written at Trinity College, Cambridge and published between 1969 and 1971, presented a theory of mammalian brain function, parts of which remain relevant to the present day, despite vast advances in neurobiology in the past decades. In 1973, Marr joined the Artificial Intelligence Laboratory at the Massachusetts Institute of Technology, where he was made a tenured full professor in 1980. Marr died in November 1980, of leukemia. His highly influential book, Vision: A Computational Investigation into the Human Representation and Processing of Visual Information, which has redefined and revitalized the study of human and machine vision, was published posthumously, in 1982, with a new edition appearing in 2010.}
}
@article{JADHAV2022127935,
title = {Scale-up of the bioelectrochemical system: Strategic perspectives and normalization of performance indices},
journal = {Bioresource Technology},
volume = {363},
pages = {127935},
year = {2022},
issn = {0960-8524},
doi = {https://doi.org/10.1016/j.biortech.2022.127935},
url = {https://www.sciencedirect.com/science/article/pii/S0960852422012688},
author = {Dipak A. Jadhav and Ashvini D. Chendake and Vandana Vinayak and Abdulaziz Atabani and Mohammad {Ali Abdelkareem} and Kyu-Jung Chae},
keywords = {Energy balance, Microbial electrochemical technology, Net energy recovery, Normalization of performance, Resource recovery, Techno-economic feasibility},
abstract = {Electrochemists and ecological engineers find environmental bioelectrochemistry appealing; however, there is a big gap between expectations and actual progress in bioelectrochemical system (BES). Implementing such technology opens new opportunities for novel electrochemical reactions for resource recovery and effective wastewater treatment. Loopholes of BES exist in its scaling-up applications, and numerous attempts toward practical applications (200, 1000, and 1500 L) are key successive indicators toward its commercialization. This review emphasized the critical rethinking of standardization of performance indices i.e. current generation (A/m2), net energy recovery (kWh/kg·COD), product/resource yield (mM), and economic feasibility ($/kWh) to make fair comparison with the existing treatment system. Therefore, directional perspectives, including modularity, energy-cost balance, energy and resource recovery, have been proposed for the sustainable market of BES. The current state of the art and up-gradation in resource recovery and contaminant removal warrants a systematic rethinking of functional worth and niches of BES for practical applications.}
}
@article{MAHMOUD202263,
title = {Where to from here? On the future development of autonomous vehicles from a cognitive systems perspective},
journal = {Cognitive Systems Research},
volume = {76},
pages = {63-77},
year = {2022},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722000444},
author = {Sara Mahmoud and Erik Billing and Henrik Svensson and Serge Thill},
keywords = {Artificial cognition, Self-driving cars, Cognitive paradigms},
abstract = {Self-driving cars not only solve the problem of navigating safely from location A to location B; they also have to deal with an abundance of (sometimes unpredictable) factors, such as traffic rules, weather conditions, and interactions with humans. Over the last decades, different approaches have been proposed to design intelligent driving systems for self-driving cars that can deal with an uncontrolled environment. Some of them are derived from computationalist paradigms, formulating mathematical models that define the driving agent, while other approaches take inspiration from biological cognition. However, despite the extensive work in the field of self-driving cars, many open questions remain. Here, we discuss the different approaches for implementing driving systems for self-driving cars, as well as the computational paradigms from which they originate. In doing so, we highlight two key messages: First, further progress in the field might depend on adapting new paradigms as opposed to pushing technical innovations in those currently used. Specifically, we discuss how paradigms from cognitive systems research can be a source of inspiration for further development in modelling driving systems, highlighting emergent approaches as a possible starting point. Second, self-driving cars can themselves be considered cognitive systems in a meaningful sense, and are therefore a relevant, yet underutilized resource in the study of cognitive mechanisms. Overall, we argue for a stronger synergy between the fields of cognitive systems and self-driving vehicles.}
}
@article{LEANZA20236716,
title = {Into the dynamics of rotaxanes at atomistic resolution††Electronic supplementary information (ESI) available: ESI Movies 1 and 2. See DOI: https://doi.org/10.1039/d3sc01593a},
journal = {Chemical Science},
volume = {14},
number = {24},
pages = {6716-6729},
year = {2023},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d3sc01593a},
url = {https://www.sciencedirect.com/science/article/pii/S2041652023062065},
author = {Luigi Leanza and Claudio Perego and Luca Pesce and Matteo Salvalaglio and Max {von Delius} and Giovanni M. Pavan},
abstract = {Mechanically-interlocked molecules (MIMs) are at the basis of artificial molecular machines and are attracting increasing interest for various applications, from catalysis to drug delivery and nanoelectronics. MIMs are composed of mechanically-interconnected molecular sub-parts that can move with respect to each other, imparting these systems innately dynamical behaviors and interesting stimuli-responsive properties. The rational design of MIMs with desired functionalities requires studying their dynamics at sub-molecular resolution and on relevant timescales, which is challenging experimentally and computationally. Here, we combine molecular dynamics and metadynamics simulations to reconstruct the thermodynamics and kinetics of different types of MIMs at atomistic resolution under different conditions. As representative case studies, we use rotaxanes and molecular shuttles substantially differing in structure, architecture, and dynamical behavior. Our computational approach provides results in agreement with the available experimental evidence and a direct demonstration of the critical effect of the solvent on the dynamics of the MIMs. At the same time, our simulations unveil key factors controlling the dynamics of these systems, providing submolecular-level insights into the mechanisms and kinetics of shuttling. Reconstruction of the free-energy profiles from the simulations reveals details of the conformations of macrocycles on the binding site that are difficult to access via routine experiments and precious for understanding the MIMs' behavior, while their decomposition in enthalpic and entropic contributions unveils the mechanisms and key transitions ruling the intermolecular movements between metastable states within them. The computational framework presented herein is flexible and can be used, in principle, to study a variety of mechanically-interlocked systems.}
}
@article{WU2025113281,
title = {Graph knowledge tracing in cognitive situation: Validation of classic assertions in cognitive psychology},
journal = {Knowledge-Based Systems},
volume = {315},
pages = {113281},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113281},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125003284},
author = {Qianxi Wu and Weidong Ji and Guohui Zhou and Yingchun Yang},
keywords = {Knowledge Tracing, Cognitive situation, Hyper-Graph Neural Network, Directed Graph Convolutional Neural Network, Cognitive psychology},
abstract = {Knowledge Tracing (KT) is a fundamental and challenging task in intelligent education, aiming to trace learners’ knowledge states and learning processes, providing better support and guidance for teaching and addressing mental factors. Previous KT tasks have focused on considering learners’ exposure to extrinsic environmental factors while ignoring the influence of intrinsic psychological factors. Moreover, previous methods have adopted a single perspective in modeling learners’ knowledge states, ignoring the diversity of states in the learning process. To address these issues, we define the concept of cognitive situation through the guidance of cognitive psychology theory to help to explain the extrinsic influence and intrinsic cognition of learners within complex learning environments. Moreover, we design a Cognitive Situation-based Graph KT (CSGKT) model to quantify learners’ influences in the cognitive process by modeling schemas capturing intrinsic characteristics and extrinsic factors through Hyper-Graph Neural Networks (HGNN). Second, we utilize a Directed Graph Convolutional Neural Network (DGCNN) to capture the correlation information between knowledge concepts and structure the learner’s cognitive activities and knowledge states, adding a detailed representation of multiple states of the learning process. In addition, we use the Erase-add Gate to filter out the knowledge states that do not match the learner’s current cognitive activities to stabilize the learner’s due cognition. In our experiments, we selected nine baseline models from three mainstream approaches, including sequence-based approaches, Transformer-based approaches, and complex structure-based approaches. The experimental results show that our models outperform these baseline models. At the same time, we also verify two classic assertions in cognitive psychology, namely, the “short-term memory forgetting of knowledge concepts is mainly caused by interference rather than memory trace fading” and the “cognitive imagery and perceptual function play an equivalent role in the cognitive process”, which further support the feasibility of the model.}
}
@article{ZHOU2025121348,
title = {Turning waste into energy through a solar-powered multi-generation system with novel machine learning-based life cycle optimization},
journal = {Chemical Engineering Science},
volume = {307},
pages = {121348},
year = {2025},
issn = {0009-2509},
doi = {https://doi.org/10.1016/j.ces.2025.121348},
url = {https://www.sciencedirect.com/science/article/pii/S000925092500171X},
author = {Jianzhao Zhou and Jingzheng Ren and Liandong Zhu and Chang He},
keywords = {Medical waste, Waste-to-energy, Multi-generation system, Machine learning, Comprehensive optimization},
abstract = {This study presents an innovative solar-powered multi-generation system aiming at converting waste into diverse forms of energy, including dimethyl ether (DME), hydrogen, power, and heat. Concurrently, a systematic and computationally efficient optimization framework is developed to unlock the maximum potential of this complex waste-to-energy system. The system integrates plasma gasification, DME synthesis, combining heat and power generation, solar-driven electrolysis and desalination. Life cycle assessment and techno-economic assessment have been implemented for system comprehensive optimization which is formulated as a large-scale nonlinear program (NLP) model. Based on rigorous process simulation results, a machine learning-based framework is proposed to accelerate optimization. Using medical waste treatment as a case study, the solution of the NLP problem reveals optimal levelized costs per kWh energy range from $0.1064 to $0.1304, with total life cycle carbon emissions ranging from 0.2748 to 0.5083 kg CO2-eq/kWh energy. The findings demonstrate the proposed system’s environmental sustainability and economic viability.}
}
@article{CROMWELL20112026,
title = {Rethinking the cognitive revolution from a neural perspective: How overuse/misuse of the term ‘cognition’ and the neglect of affective controls in behavioral neuroscience could be delaying progress in understanding the BrainMind},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {35},
number = {9},
pages = {2026-2035},
year = {2011},
note = {Pioneering Research in Affective Neuroscience: Celebrating the Work of Dr. Jaak Panksepp},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2011.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0149763411000273},
author = {Howard Casey Cromwell and Jaak Panksepp},
keywords = {Cognition, Emotion, Motivation, Perception, Concepts, Neural activity, Behavior},
abstract = {Words such as cognition, motivation and emotion powerfully guide theory development and the overall aims and goals of behavioral neuroscience research. Once such concepts are accepted generally as natural aspects of the brain, their influence can be pervasive and long lasting. Importantly, the choice of conceptual terms used to describe and study mental/neural functions can also constrain research by forcing the results into seemingly useful ‘conceptual’ categories that have no discrete reality in the brain. Since the popularly named ‘cognitive revolution’ in psychological science came to fruition in the early 1970s, the term cognitive or cognition has been perhaps the most widely used conceptual term in behavioral neuroscience. These terms, similar to other conceptual terms, have potential value if utilized appropriately. We argue that recently the term cognition has been both overused and misused. This has led to problems in developing a usable shared definition for the term and to promotion of possible misdirections in research within behavioral neuroscience. In addition, we argue that cognitive-guided research influenced primarily by top-down (cortical toward subcortical) perspectives without concurrent non-cognitive modes of bottom-up developmental thinking, could hinder progress in the search for new treatments and medications for psychiatric illnesses and neurobehavioral disorders. Overall, linkages of animal research insights to human psychology may be better served by bottom-up (subcortical to cortical) affective and motivational ‘state-control’ perspectives, simply because the lower networks of the brain are foundational for the construction of higher ‘information-processing’ aspects of mind. Moving forward, rapidly expanding new techniques and creative methods in neuroscience along with more accurate brain concepts, may help guide the development of new therapeutics and hopefully more accurate ways to describe and explain brain-behavior relationships.}
}
@article{PRASAD2023104,
title = {Irrigation development under uncertainty: A call for adaptive investment pathways},
journal = {Environmental Science & Policy},
volume = {140},
pages = {104-110},
year = {2023},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2022.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S1462901122003653},
author = {Pooja Prasad and Annelieke Duker and Charlotte {de Fraiture} and Pieter {van der Zaag}},
keywords = {Adaptation pathways, Irrigation, Investments, Uncertainty, Development, Sub-Saharan Africa},
abstract = {There is an urgent need in sub-Saharan Africa (SSA) to enhance irrigation access to meet the challenges of growing population and climate risk. To achieve this, big investments are currently planned in large irrigation infrastructure. We believe there is danger in following this conventional approach, which requires big lumpsum investments, locking large capital into projects that do not adapt to deep uncertainties from climatic or socio-political factors. Instead, in this Perspective article, we propose an alternate “adaptive investment pathways” (AdIP) approach for planning step-wise investments towards desired objectives, implemented progressively depending on how the future unfolds, in order to gain flexibility. AdIP extends the adaptation pathways concept, which refers to a sequence of actions to be taken in response to a changing reality, and applies it to the context of development under uncertainty. Monitoring and learning is at the heart of this approach, which ensures that the plan adapts as new knowledge becomes available. Thus, AdIP internalizes risk and reduces chances of failures. For financial institutions backing development projects, following a pathway of smaller de-centralized investments lowers risk and incorporates a learning approach that allows re-thinking and adapting along the path. We illustrate the AdIP approach using the case of ephemeral sand river based small-scale irrigation in the drylands of SSA. We conclude that in face of deep uncertainties, the path to successful irrigation development in SSA requires a shift from making few large upfront investments in large-scale projects to making large numbers of smaller investments that assure flexibility.}
}
@article{WU2020242,
title = {Mentalizing during social InterAction: A four component model},
journal = {Cortex},
volume = {126},
pages = {242-252},
year = {2020},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2019.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0010945220300277},
author = {Haiyan Wu and Xun Liu and Cindy C. Hagan and Dean Mobbs},
keywords = {Metacognition, Mentalizing, Vicarious mentalizing, Co-mentalizing, Social inference},
abstract = {Mentalizing, conventionally defined as the process in which we infer the inner thoughts and intentions of others, is a fundamental component of human social cognition. Yet its role, and the nuanced layers involved, in real world social interaction are rarely discussed. To account for this lack of theory, we propose the interactive mentalizing theory (IMT) -to emphasize the role of metacognition in different mentalizing components. We discuss the connection between mentalizing, metacognition, and social interaction in the context of four elements of mentalizing: (i) Metacognition–inference of our own thought processes and social cognitions and which is central to all other components of mentalizing including: (ii) first-order mentalizing–inferring the thoughts and intentions of an agent's mind; (iii) personal second-order mentalizing–inference of other's mentalizing of one's own mind; (iv) Collective mentalizing: which takes at least two forms (a) vicarious mentalizing: adopting another's mentalizing of an agent (i.e., what we think others think of an agent) and (b) co-mentalizing: mentalizing about an agent in conjunction with others' mentalizing of that agent (i.e., conforming to others beliefs about another agent's internal states). The weights of these four elements is determined by metacognitive insight and confidence in one's own or another's mentalizing ability, yielding a dynamic interaction between these circuits. To advance our knowledge on mentalizing during live social interaction, we identify how these subprocesses can be organized by different target agents and facilitated by combining computational modeling and interactive brain approaches.}
}
@incollection{MCCALL20231025,
title = {Chapter 57 - Advances in ethics for the neuroscience agenda∗},
editor = {Michael J. Zigmond and Clayton A. Wiley and Marie-Francoise Chesselet},
booktitle = {Neurobiology of Brain Disorders (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {1025-1045},
year = {2023},
isbn = {978-0-323-85654-6},
doi = {https://doi.org/10.1016/B978-0-323-85654-6.00053-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323856546000538},
author = {Iris Coates McCall and Veljko Dubljević},
keywords = {Animal models, Biomedical science, Data sharing, Ethics, Health, Incidental finding, Neuroscience, Public policy, Science communication},
abstract = {Critical thinking about ethics in neuroscience can be a powerful force in enabling research and translating results meaningfully for society. In this chapter, we strive to give those new to neuroscience investigation, as well as more experienced investigators, an introduction to the field of neuroethics such that they may begin to incorporate it into their future work from its very inception. We begin with an overview of the regulatory and oversight mechanisms currently in place that guide the ethical conduct of neuroscience research, followed by an introduction to four of the most salient neuroethics topics relevant to neuroscience research—research with animals, data sharing, incidental findings, and neuroscience communication. First, we discuss how upfront consideration of the societal implications of advances in neuroscience can shape the use of animal models. We situate ethical thinking in this era of big science and big data, reflecting on strategies for sharing databases while protecting contributors and users. Next, we highlight how collaboration among neuroscientists, ethicists, and others can produce positive measures to resolve the problem of incidental discoveries in brain imaging research, as one example of debates on incidental findings more broadly. Third, we discuss the importance of effective and responsible communication of neuroscience research and information. Finally, the mandate of neuroscience research as public service and ethical imperative is addressed by describing opportunities for neuroscientists to engage with societal issues emerging from their research and how this deepens the discourse and adds value to the research enterprise.}
}
@article{ALLISON2018147,
title = {Dilemmas of modelling and decision-making in environmental research},
journal = {Environmental Modelling & Software},
volume = {99},
pages = {147-155},
year = {2018},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2017.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S1364815217300749},
author = {Andrew E.F. Allison and Mark E. Dickson and Karen T. Fisher and Simon F. Thrush},
keywords = {Wicked problems, Agent-based modelling, Post-normal science, Social-ecological systems, Shallow coastal systems},
abstract = {Multiple dilemmas confound social-ecological modelling. This review paper focuses on two: a modeller's dilemma associated with determining appropriate levels of model simplification, and a dilemma of decision-making relating to the use of models that were never designed to predict. We analyse approaches for addressing these dilemmas as they relate to shallow coastal systems and conclude that wicked problems cannot be adequately addressed using traditional disciplinary or systems engineering modelling. Simplified inter- and trans-disciplinary models have the potential to identify directions of system change, challenge thinking in disciplinary silos, and ultimately confront the dilemmas of social-ecological modelling.}
}
@article{TANTILLO2021n/a,
title = {Dynamic effects on organic reactivity—Pathways to (and from) discomfort},
journal = {Journal of Physical Organic Chemistry},
volume = {34},
number = {6},
pages = {n/a},
year = {2021},
issn = {0894-3230},
doi = {https://doi.org/10.1002/poc.4202},
url = {https://www.sciencedirect.com/science/article/pii/S0894323022006889},
author = {Dean J. Tantillo},
keywords = {bifurcation, dynamics, entropy},
abstract = {Recent computational studies highlighting the importance of accounting for dynamic effects on organic reactivity are discussed, accompanied by descriptions of the factors that led the author to pursue these projects.}
}